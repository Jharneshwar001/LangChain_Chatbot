{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JexwZ4MfxbHL",
    "outputId": "2c357264-4df6-437d-a8a4-d141568db75a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
      "Requirement already satisfied: langchain_pinecone in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
      "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
      "Requirement already satisfied: unstructured in /usr/local/lib/python3.10/dist-packages (0.15.12)\n",
      "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.0)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.125)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.5.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: pinecone-client<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (5.0.1)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.46.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
      "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.4)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.3)\n",
      "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.13.0)\n",
      "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2024.4.27)\n",
      "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.9.7)\n",
      "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.2)\n",
      "Requirement already satisfied: unstructured-client in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.25.9)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.66.5)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.9.5)\n",
      "Requirement already satisfied: python-oxmsg in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.0->langchain_community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain_community) (24.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain_community) (3.10.7)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.7.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (2024.8.30)\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (1.1.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (0.0.7)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (2.0.7)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.6)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->unstructured) (1.16.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.4.2)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.10/dist-packages (from python-oxmsg->unstructured) (0.47)\n",
      "Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (43.0.1)\n",
      "Requirement already satisfied: deepdiff>=6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (8.0.1)\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.6)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.6.0)\n",
      "Requirement already satisfied: pypdf>=4.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (5.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (2.8.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain_openai) (1.2.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
      "Requirement already satisfied: orderly-set==5.2.2 in /usr/local/lib/python3.10/dist-packages (from deepdiff>=6.0->unstructured-client->unstructured) (5.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.0->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.0->langchain_community) (2.23.4)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install \\\n",
    "langchain_community \\\n",
    "langchain_pinecone \\\n",
    "langchain_openai \\\n",
    "unstructured \\\n",
    "langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGqc4VzZxnDT"
   },
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bw15fJoMbNhQ",
    "outputId": "30528a8f-e2eb-492d-8243-06ff3d5dc0d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (5.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RSlz7Aakx-q7",
    "outputId": "7cabbc1b-890f-4e8c-a591-dc0e7c8032db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/content/sample_data/data/Unit-4_DL.pdf', 'page': 0}, page_content='Unit -4 \\n \\nWord similarity is a fundamental concept in natural language processing, and there are several \\napplications where measuring the similarity or relatedness between words is crucial. Some of these \\napplications include:  \\n1. Information Retrieval : In information retrieval systems, understanding the similarity between \\nuser queries and documents is essential for ranking search results. Word similarity measures can \\nhelp identify documents that are semantically related to a user\\'s query.  \\n2. Text Summarization : When generating text summaries, it\\'s important to ensure that the \\nsummary captures the key information in a document. Word similarity can be used to identify \\nimportant words and phrases in the source text and select them for inclusion in the summary.  \\n3. Mac hine Translation : In machine translation systems, word similarity can be useful for aligning \\nwords in the source and target languages. Measuring similarity between words in different \\nlanguages can aid in selecting appropriate translations.  \\n4. Lexical Semantic s: Word similarity is a valuable resource in lexical semantics. It can be used to \\ndiscover synonyms, antonyms, hypernyms, and hyponyms. Lexical databases and lexical \\nontologies often rely on word similarity measures to organize and relate words.  \\n5. Word Sense  Disambiguation : Word sense disambiguation is the task of determining the correct \\nsense of a word in context. Word similarity can help disambiguate words by comparing the \\ncontext in which a word appears with the various senses of that word.  \\n6. Semantic Search  and Recommendation Systems : In search engines and recommendation \\nsystems, word similarity can be used to find documents, products, or content that is semantically \\nsimilar to a user\\'s query or interests. This helps improve the relevance of search results a nd \\nrecommendations.  \\n7. Plagiarism Detection : Detecting plagiarism often involves comparing the similarity of text \\npassages. Word similarity measures can be used to identify similarities between documents and \\nhighlight potential instances of plagiarism.  \\n8. Word E mbeddings : Word embeddings, such as Word2Vec, GloVe, and FastText, are trained to \\ncapture word similarity in vector space. These embeddings are widely used in various NLP tasks, \\nand they provide a way to quantify word similarity based on the distributional  hypothesis, which \\nstates that words with similar meanings tend to occur in similar contexts.  \\n9. Analogical Reasoning : Word similarity is a key component of analogical reasoning tasks. \\nModels like Word2Vec have been used to solve analogical word relationships , such as \"king - \\nman + woman = queen,\" by leveraging word similarity.  \\nIn all these applications, the choice of word similarity measure or embedding technique depends on the \\nspecific requirements of the task and the corpus of text data being analyzed. Diff erent measures, such as '),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-4_DL.pdf', 'page': 1}, page_content='cosine similarity, Jaccard similarity, or specialized word embeddings, may be more suitable for different \\nuse cases.  \\n \\nAnalogy reasoning  \\nAnalogy reasoning is a cognitive process where you identify relationships between words or conce pts and \\napply these relationships to draw conclusions or make inferences. In the context of natural language \\nprocessing (NLP) and machine learning, analogy reasoning often involves finding relationships between \\nwords or phrases and solving analogical word problems, such as \"king - man + woman = queen.\" This \\ntask has been used to evaluate the capabilities of word embeddings and language models in capturing \\nsemantic relationships between words. Here\\'s how analogy reasoning is applied:  \\n1. Word Embeddings : Word em beddings are dense vector representations of words in a continuous \\nvector space. Techniques like Word2Vec, GloVe, and FastText have become popular for learning \\nword embeddings. In these vector spaces, word vectors are expected to capture semantic \\nrelations hips between words, allowing for analogy reasoning.  \\n2. Vector Arithmetic : Analogy reasoning typically involves simple vector arithmetic with word \\nembeddings. For example, in the analogy \"king - man + woman = queen,\" you would represent \\n\"king,\" \"man,\" \"woman,\"  and \"queen\" as vectors. Then, you subtract the vector for \"man\" from \\n\"king,\" add the vector for \"woman,\" and look for the closest vector in the embedding space to the \\nresult. The closest vector is expected to be the vector for \"queen.\"  \\n3. Similarity Metrics : Cosine similarity is commonly used to measure the similarity between vectors \\nin word embedding spaces. In the example above, you would calculate the cosine similarity \\nbetween the resulting vector and all vectors in the embedding space to find the most sim ilar word \\n(in this case, \"queen\").  \\n4. Analogical Reasoning Datasets : Datasets like the Word2Vec analogy dataset or the Google \\nAnalogy Test Set provide a set of analogy questions for evaluating word embeddings and models\\' \\nability to perform analogy reasoning. These datasets contain analogy questions in the form of \"A \\nis to B as C is to ?\" and provide a target word that models should predict.  \\n5. Transfer Learning : Analogy reasoning can be used as a task for transfer learning. Models pre -\\ntrained on large text corpor a, like BERT or GPT -3, can perform analogy reasoning because they \\nhave learned a wide range of word relationships during pre -training. Fine -tuning these models on \\nspecific analogy datasets can further improve their performance on analogy tasks.  \\n6. Evaluating Model Performance : Analogy reasoning tasks are used to assess the quality of word \\nembeddings and language models. If a model can accurately solve a wide range of analogical word \\nproblems, it suggests that the model has learned meaningful semantic relations hips between words.  \\nAnalogical reasoning is not limited to word relationships but can also be applied to more complex \\nconcepts, including logical reasoning and semantic relationships in general. It plays a crucial role in \\nevaluating the quality of word emb eddings and the capabilities of language models in understanding and \\ngenerating human -like language.  '),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-4_DL.pdf', 'page': 2}, page_content=' \\n \\nNamed Entity Recognition (NER ) \\nNamed Entity Recognition (NER) is a natural language processing (NLP) task that involves identifying \\nand classifying named entities in a text, such as names of people, organizations, locations, dates, and other \\nspecific entities. NER is a fundamental task in information extraction and text analysis, and it has \\nnumerous practical applications, including inform ation retrieval, question answering, text summarization, \\nand more. Here\\'s how NER works:  \\n1. Input Text : NER begins with a piece of text as input, which can be a sentence, a paragraph, a \\ndocument, or even a stream of text.  \\n2. Tokenization : The text is first token ized into words or subword units. This step breaks the text \\ninto smaller units that can be analyzed independently. Tokenization is often the first step in NLP \\npreprocessing.  \\n3. Named Entity Recognition : The main task of NER is to classify each token or word i n the text \\ninto one of several predefined categories. Common categories include:  \\n• Person: Names of individuals.  \\n• Organization: Names of companies, institutions, etc.  \\n• Location: Names of places, cities, countries, etc.  \\n• Date: Expressions representing dates or t imes.  \\n• Numeric Values: Numbers and other numerical expressions.  \\n• Miscellaneous: Other named entities that do not fit into the above categories.  \\n4. Sequence Labeling : NER is typically treated as a sequence labeling problem, where each token is \\nlabeled with its e ntity category. For example, given the sentence \"Apple Inc. is headquartered in \\nCupertino, California,\" the NER output might look like:  \\n• \"Apple Inc.\" -> Organization  \\n• \"Cupertino\" -> Location  \\n• \"California\" -> Location  \\n5. Training Data : To train an NER model, you need a labeled dataset where each token is annotated \\nwith its correct entity category. Annotated corpora like CoNLL -2003 and OntoNotes provide \\ntraining and evaluation data for NER models.  \\n6. NER Models : NER can be approached using various machine learning and  deep learning \\ntechniques, including:  '),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-4_DL.pdf', 'page': 3}, page_content=\"• Rule -based systems: These systems use handcrafted rules to identify entities based on \\npatterns and dictionaries.  \\n• Conditional Random Fields (CRF): CRF models can capture sequential dependencies in \\nthe data and are widel y used for NER.  \\n• Recurrent Neural Networks (RNNs): Early NER models used RNNs and LSTMs to \\ncapture context in a sequence of words.  \\n• Transformer -based models: Modern NER models, including BERT, GPT -3, and others, \\nleverage transformer architecture and pre -trained language models for improved \\nperformance.  \\n7. Evaluation : NER models are evaluated based on metrics like precision, recall, and F1 -score, \\nwhich measure the accuracy of entity recognition and classification.  \\n8. Applications : NER is used in a wide range of applications, including information retrieval, \\ndocument classification, chatbots, and more. For example, in a news article, NER can be used to \\nidentify the names of people and organizations, making it easier to retrieve relevant information \\nor categorize t he content.  \\nNER is an essential component of many NLP systems, enabling them to extract structured information \\nfrom unstructured text data. The choice of NER model and its performance depend on the specific use \\ncase and the quality and size of the training  data.  \\n \\nOpinion Mining  \\nOpinion mining, also known as sentiment analysis, is the process of determining the sentiment or emotion \\nexpressed in a piece of text, such as positive, negative, neutral, or a specific sentiment category. Recurrent \\nNeural Networks (RNNs) have been used for opinion mining due to their ability to capture sequential \\ndependencies in text data. Here's how RNNs can be applied to opinion mining:  \\n1. Data Preprocessing : The first step in opinion mining is to prepare the text data. This  may involve \\ntokenization, removing stop words, and other text preprocessing tasks to clean and standardize the \\ntext. \\n2. Text Representation : Text data needs to be converted into a numerical format that can be used as \\ninput for the RNN. Common text representa tions include word embeddings (e.g., Word2Vec, \\nGloVe) or one -hot encoding.  \\n3. Labeling : For opinion mining, you need labeled data where each text sample is associated with a \\nsentiment label (e.g., positive, negative, neutral). This labeled data is used to tra in and evaluate the \\nRNN model.  \\n4. Model Architecture : Recurrent Neural Networks (RNNs) are particularly useful for handling \\nsequences of data, such as sentences or paragraphs. The simplest RNN architecture processes text \\nsequentially, word by word. However, d ue to challenges like vanishing gradients, more advanced \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-4_DL.pdf', 'page': 4}, page_content=\"RNN variants, such as Long Short -Term Memory (LSTM) and Gated Recurrent Unit (GRU), are \\noften used.  \\n5. Sequence Modeling : RNNs can capture sequential dependencies in text, allowing them to \\nunderstand ho w the sentiment evolves throughout a sentence or document. The model processes \\nthe input text sequentially and maintains an internal state that considers previous words in the \\nsequence.  \\n6. Sentiment Classification : The RNN model predicts the sentiment label f or each input text. \\nTypically, a softmax layer is used at the output to classify the sentiment into predefined categories \\n(e.g., positive, negative, neutral).  \\n7. Training : The RNN model is trained on the labeled data using a suitable loss function (e.g., \\ncategorical cross -entropy). Backpropagation through time (BPTT) is applied to update the model's \\nparameters, and optimization algorithms like Adam or SGD are used to minimize the loss.  \\n8. Evaluation : The model's performance is evaluated on a separate validation o r test dataset using \\nmetrics like accuracy, precision, recall, F1 -score, or others, depending on the specific problem.  \\n9. Regularization and Hyperparameter Tuning : Techniques like dropout, early stopping, and \\nhyperparameter tuning are used to improve the mode l's performance and prevent overfitting.  \\n10. Inference : Once the model is trained and evaluated, it can be used to perform sentiment analysis \\non new, unlabeled text data. The model predicts the sentiment of the text as positive, negative, or \\nneutral.  \\n11. Applicati ons: Opinion mining using RNNs has various applications, including social media \\nsentiment analysis, product reviews analysis, customer feedback analysis, and brand monitoring. \\nIt can help businesses and organizations understand public opinion and make data -driven \\ndecisions.  \\nIt's worth noting that while RNNs are suitable for sequential data like text, more recent models, such as \\nTransformers (e.g., BERT, GPT -3), have shown significant improvements in sentiment analysis tasks due \\nto their ability to capture l ong-range dependencies and contextual information. Depending on the scale \\nand specific requirements of your sentiment analysis task, you may also consider using pre -trained \\ntransformer models for improved accuracy.  \\n \\n \\n \\n \\n \\nParsing and Sentiment Analysis using  Recursive Neural Networks  \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-4_DL.pdf', 'page': 5}, page_content=\"Recursive Neural Networks (RNNs) are a type of neural network architecture that can be used for parsing \\nand sentiment analysis tasks. Here's how RNNs can be applied to both tasks:  \\n1. Parsing with Recursive Neural Networks : \\nParsing is the task of analyzing the grammatical structure of a sentence, typically represented as a parse \\ntree. Recursive Neural Networks (RNNs) can be employed to construct parse trees for sentences. Here's \\nhow it works:  \\n• Tree Structured Parsing : In a rec ursive neural network for parsing, the input sentence is \\nrecursively split into smaller substructures, such as phrases or sub -clauses. Each \\nsubstructure is represented as a vector using neural networks.  \\n• Compositionality : Recursive neural networks use compo sitionality to construct parse \\ntrees. When two substructures are combined into a larger one, the network applies a \\ncomposition function to create a new representation for the larger structure.  \\n• Dependency Parsing : Recursive neural networks can also be used for dependency parsing, \\nwhere the relationships between words in a sentence are represented as a directed acyclic \\ngraph (DAG). The network assigns dependencies between words, capturing syntactic \\nrelationships.  \\n• Supervised Learning : To train a recursive neural network for parsing, you need a labeled \\ndataset with parse trees for sentences. The network learns to predict the correct parse tree \\nstructure for a given input sentence.  \\n• Applications : Parsing is fundamental in natural language understandi ng and generation \\ntasks. It is used in information extraction, machine translation, question answering, and \\nmany other NLP applications.  \\n2. Sentiment Analysis with Recursive Neural Networks : \\nSentiment analysis involves determining the sentiment or emotion exp ressed in a piece of text. Recursive \\nneural networks can be used to perform sentiment analysis by capturing hierarchical sentiment information \\nin complex sentences. Here's how it works:  \\n• Recursive Structure for Sentiment : Recursive neural networks can be de signed to build \\na recursive structure for sentences, where the sentiment at each level of the tree is calculated \\nbased on the sentiments of its subparts. This captures the sentiment compositionally.  \\n• Sentiment Classification : At the leaf nodes of the parse tree, individual words or phrases \\nare assigned sentiment labels (e.g., positive, negative, neutral). The network then combines \\nthese labels in a hierarchical manner to determine the overall sentiment of the sentence.  \\n• Supervised Learning : To train a recursi ve neural network for sentiment analysis, you need \\na labeled dataset where each sentence is associated with its sentiment label. The network \\nlearns to predict the sentiment of a sentence based on its structure.  \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-4_DL.pdf', 'page': 6}, page_content=\"• Applications : Sentiment analysis is widely us ed in applications such as social media \\nmonitoring, product reviews analysis, customer feedback analysis, and market research to \\nunderstand public opinion and sentiment towards specific topics or products.  \\nIt's important to note that while Recursive Neural  Networks can be used for parsing and sentiment analysis, \\nmore recent neural network architectures, such as Transformer -based models, have shown significant \\nimprovements in these tasks. Transformers, with their self -attention mechanisms, can capture long -range \\ndependencies and contextual information more effectively. Therefore, depending on the specific \\nrequirements and the scale of your parsing and sentiment analysis tasks, you may also want to consider \\nusing Transformer -based models for improved accuracy.  \\n \\nSentence classification using Convolutional Neural Networks (CNNs)  \\nSentence classification using Convolutional Neural Networks (CNNs) is a natural language processing \\n(NLP) task where you aim to classify a given sentence into predefined categories or lab els. CNNs, which \\nare commonly associated with image processing, can also be adapted to process sequential data like text \\neffectively. Here's how CNNs can be applied to sentence classification:  \\n1. Data Preparation : \\n• Text Preprocessing : The first step is to prep rocess the input sentences. This may involve \\ntokenization, lowercasing, removing punctuation, and other text cleaning tasks.  \\n• Word Embeddings : Convert words in the sentences into word embeddings, such as \\nWord2Vec, GloVe, or FastText vectors. Word embeddings  capture semantic information \\nabout words and can be used to represent words as vectors.  \\n2. Sentence Representation : \\n• Padding : Sentences may have varying lengths, so you need to pad or truncate them to \\nensure they have a consistent length. Padding adds zeros t o shorter sentences, and \\ntruncation removes words from longer sentences.  \\n• Embedding Layer : Input word embeddings are fed into an embedding layer that converts \\nwords in the sentence into numerical vectors.  \\n3. Convolutional Layers : \\n• Convolutional Filters : CNNs use convolutional filters to capture local patterns and \\nfeatures in the sentence. The filters slide over the sentence to extract different features.  \\n• Pooling Layers : After convolution, max -pooling or average -pooling layers are often \\napplied to reduce t he dimensionality and focus on the most important features.  \\n• Multiple Filters : Multiple filters with different kernel sizes can be used to capture features \\nof varying lengths in the sentence.  \\n4. Flattening and Fully Connected Layers : \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-4_DL.pdf', 'page': 7}, page_content=\"• The output from the convol utional and pooling layers is typically flattened into a 1D vector.  \\n• Fully connected layers can be added to perform higher -level feature extraction and \\ndecision -making.  \\n5. Output Layer : \\n• The output layer consists of one or more neurons (depending on the number of classes) \\nwith softmax activation for multi -class classification or sigmoid activation for binary \\nclassification.  \\n• It produces class probabilities or scores.  \\n6. Training : \\n• Train the CNN model using labeled data (sentences with their corresponding categories o r \\nlabels) with a suitable loss function (e.g., categorical cross -entropy for multi -class \\nclassification).  \\n• Use optimization algorithms like Adam or SGD to minimize the loss.  \\n7. Evaluation : \\n• Evaluate the model's performance on a separate validation or test datas et using metrics like \\naccuracy, precision, recall, F1 -score, or others, depending on the specific classification \\nproblem.  \\n8. Regularization and Hyperparameter Tuning : \\n• Apply regularization techniques like dropout and L2 regularization to prevent overfitting.  \\n• Fine-tune hyperparameters, including the number of filters, filter sizes, learning rate, and \\nbatch size.  \\n9. Inference : \\n• Once the model is trained and evaluated, you can use it to classify new sentences into the \\npredefined categories or labels.  \\n10. Applications : \\n• Sentence classification using CNNs has numerous applications, including document \\ncategorization, spam detection, sentiment analysis, topic classification, and more.  \\nIt's important to note that while CNNs can be effective for sentence classification tasks, mor e recent \\narchitectures like Transformers, especially models pre -trained on large text corpora (e.g., BERT, GPT -3), \\nhave achieved state -of-the-art performance in many NLP classification tasks. Depending on the scale and \\nrequirements of your sentence classif ication task, you may also want to consider using Transformers for \\nimproved accuracy.  \\n \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-4_DL.pdf', 'page': 8}, page_content='Dialogue generation with Long Short -Term Memory (LSTM) networks  \\nDialogue generation with Long Short -Term Memory (LSTM) networks is a task in natural language \\nprocessing (NLP) that involves creating conversational responses or generating dialogues in a human -like \\nmanner. LSTMs are a type of recurrent neural network (RNN) that can capture sequential dependencies \\nin data, making them suitable for generating cohere nt and contextually relevant responses in a dialogue. \\nHere\\'s an overview of how dialogue generation with LSTMs can be accomplished:  \\nData Preparation:  \\n1. Dataset : Gather a dataset of conversational data, which includes pairs of utterances or dialogues. \\nEach di alogue typically consists of a sequence of user inputs and system responses. You can collect \\ndialogues from various sources, including social media, chat logs, or create synthetic dialogues.  \\n2. Tokenization : Tokenize the text, splitting it into words or subwo rd units. Tokenization is crucial \\nfor preparing the data for LSTM input.  \\n3. Word Embeddings : Convert the tokenized words into word embeddings (e.g., Word2Vec, \\nGloVe) to represent words as dense vectors. These embeddings capture semantic information about \\nword s. \\nModel Architecture:  \\n4. Sequence -to-Sequence Model : Use a sequence -to-sequence model, which consists of an encoder \\nand a decoder. LSTMs are often used as the building blocks of both the encoder and decoder.  \\n• Encoder : The encoder processes the user\\'s input se quence and encodes it into a fixed -size \\ncontext vector that captures the context of the conversation. Each word in the input \\nsequence is fed into the LSTM one at a time, and the final hidden state of the encoder \\nLSTM becomes the context vector.  \\n• Decoder : The decoder generates the system\\'s response sequence based on the context \\nvector. It uses another LSTM to produce one word at a time while considering the context \\nvector and previously generated words.  \\n5. Teacher Forcing : During training, the decoder is often t rained using a technique called \"teacher \\nforcing,\" where the actual system responses from the training data are used as inputs to the decoder \\nat each step. This helps stabilize training.  \\n6. Attention Mechanism : To improve the generation of contextually releva nt responses, you can \\nincorporate an attention mechanism into the model. Attention allows the model to focus on specific \\nparts of the input sequence when generating each word in the response.  \\nTraining:  \\n7. Loss Function : Train the dialogue generation model usi ng a suitable loss function, such as \\ncategorical cross -entropy, which measures the dissimilarity between the generated response and \\nthe ground truth response.  '),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-4_DL.pdf', 'page': 9}, page_content=\"8. Optimization : Use optimization techniques like stochastic gradient descent (SGD) or Adam to \\nminim ize the loss function.  \\nEvaluation:  \\n9. Validation and Testing : Evaluate the model's performance on a validation dataset using metrics \\nsuch as BLEU score, ROUGE score, perplexity, or human judgment. These metrics assess the \\nquality of the generated responses.  \\nInference:  \\n10. Dialogue Generation : In the inference phase, use the trained model to generate responses during \\nreal-time conversations. Given a user's input, the encoder produces a context vector, and the \\ndecoder generates the system's response one word at a time.  \\nApplications:  \\nDialogue generation with LSTMs has applications in chatbots, virtual assistants, customer support, and \\nany scenario where interactive and context -aware conversations are required.  \\nIt's worth noting that while LSTMs can produce coherent dialogue, more recent models like Transformer -\\nbased models (e.g., GPT -3) have demonstrated superior performance in dialogue generation tasks, thanks \\nto their ability to capture longer -range dependencies and context. Depending on your requirements, you \\nmay also consider using such advanced models for dialogue generation.  \\n \\nDynamic Memory Networks in NLP  \\nDynamic Memory Networks (DMNs) are a type of neural network architecture designed for question -\\nanswering and reasoning tasks in natural language processing (NLP). They are particularly well -suited for \\ntasks that involve reading a passage of text and then answering questions based on the information in the \\npassage. Here are some applications of Dynamic Memory Networks in NLP:  \\n1. Question Answering : DMN s can be used to answer questions based on a given context or passage \\nof text. They read the context, reason over it, and generate answers to questions. This is useful for \\ntasks like reading comprehension, where the model needs to extract specific informat ion from a \\ntext to answer questions accurately.  \\n2. Document Retrieval : DMNs can be used to retrieve relevant documents from a large corpus in \\nresponse to a query. By dynamically updating their memory, they can store and retrieve relevant \\ndocuments efficiently  for a given query, making them suitable for information retrieval tasks.  \\n3. Text Summarization : DMNs can be applied to text summarization tasks, where they read and \\nunderstand the content of a document and generate concise and coherent summaries that capture  \\nthe essential information.  \\n4. Textual Entailment : DMNs can be used to determine the logical relationships between pairs of \\ntext, such as recognizing whether one text entails, contradicts, or is neutral with respect to another \\ntext. This is valuable for tasks  like recognizing textual entailment or natural language inference.  \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-4_DL.pdf', 'page': 10}, page_content='5. Story or Dialogue Understanding : DMNs can be applied to understanding and reasoning over \\nstories or dialogues. They read the context, track entities and events, and answer questions or \\npredict the next turn in a dialogue. This is useful for chatbots, virtual assistants, and narrative \\nunderstanding tasks.  \\n6. Semantic Role Labeling : DMNs can be used to identify and label the semantic roles of words or \\nphrases in a sentence. They can capture the relationships between words and their roles in the \\ncontext of a sentence.  \\n7. Information Extraction : DMNs can assist in information extraction tasks by reading documents \\nand extracting structured information, such as events, entities, and relationships from u nstructured \\ntext. \\n8. Sentiment Analysis : While DMNs are not the primary choice for sentiment analysis, they can be \\napplied to understand and reason about the sentiment expressed in a piece of text by capturing the \\ncontext and relationships between words.  \\n9. Comm onsense Reasoning : DMNs can be used to reason about common sense and background \\nknowledge to answer questions or make inferences that require general world knowledge.  \\n10. Medical Diagnosis : In the medical domain, DMNs can assist in diagnosing medical condition s by \\nreading patient records, medical literature, and other sources of information to provide accurate \\ndiagnoses and treatment recommendations.  \\nIt\\'s important to note that DMNs were a step towards addressing complex reasoning in NLP, but they have \\nbeen suc ceeded by more advanced models, such as Transformers (e.g., BERT, GPT -3), which have \\nachieved state -of-the-art performance in various NLP tasks. These models are capable of handling \\ndynamic memory and have become the primary choice for many NLP application s. However, DMNs and \\ntheir principles have contributed to the development of these more advanced architectures.  \\n \\nFactoid question answering  \\nFactoid question answering is a natural language processing (NLP) task that focuses on answering \\nquestions that requ ire specific, concise, and often factual answers. These answers can typically be found \\nwithin a given corpus of text, and the task involves extracting the relevant information from the text to \\nrespond accurately to the question. Factoid question answering is widely used in search engines, chatbots, \\nvirtual assistants, and other information retrieval systems. Here are some key aspects of factoid question \\nanswering:  \\n1. Question Types : Factoid questions typically begin with words like \"who,\" \"what,\" \"where,\" \\n\"whe n,\" \"why,\" or \"how.\" These questions seek specific and objective information, such as names, \\ndates, numbers, locations, and descriptions.  \\n2. Corpus of Text : Factoid question answering systems are trained on or provided with a corpus of \\ntext data, such as docu ments, articles, books, websites, or databases. This text corpus serves as the \\nknowledge source from which answers are extracted.  '),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-4_DL.pdf', 'page': 11}, page_content=\"3. Answer Extraction : The primary goal of factoid question answering is to identify and extract the \\nspecific information that directly answers the question. This often involves finding a portion of \\ntext, such as a sentence or a phrase, that contains the answer.  \\n4. Named Entity Recognition (NER) : Named entity recognition is a critical component of factoid \\nquestion an swering. It involves identifying and categorizing entities like people, organizations, \\nlocations, dates, and more in the text, as these entities are often the subjects of factoid questions.  \\n5. Information Retrieval Techniques : Factoid question answering syste ms may use information \\nretrieval techniques to identify relevant documents or passages within the corpus. Techniques like \\nTF-IDF (Term Frequency -Inverse Document Frequency) or document ranking methods help \\npinpoint the most likely sources of the answer.  \\n6. Answer Ranking : In cases where multiple possible answers exist in the text, answer ranking \\nmethods are employed to determine the most likely correct answer. This can include evaluating \\nthe context and relevance of the answer candidates.  \\n7. Machine Learning Mode ls: Machine learning models, including deep learning models like \\nTransformers, are commonly used for factoid question answering. These models can process and \\nunderstand textual data and make predictions about the answers based on the input question.  \\n8. Evalua tion Metrics : The performance of factoid question answering systems is often evaluated \\nusing metrics like precision, recall, F1 -score, accuracy, and others. These metrics assess how well \\nthe system extracts and correctly identifies answers.  \\n9. Applications : Factoid question answering is applied in various domains, including search engines \\n(e.g., Google's Knowledge Graph), virtual assistants (e.g., Siri, Alexa), customer support chatbots, \\nand information retrieval systems for specific domains like medical, lega l, and finance.  \\n10. Challenges : Factoid question answering can be challenging due to the diversity of questions, \\npotential ambiguity, and the need to understand context. Moreover, the quality and coverage of the \\nunderlying text corpus play a significant role i n the system's performance.  \\nFactoid question answering is a foundational task in NLP and forms the basis for more advanced question -\\nanswering systems, which can handle more complex questions and provide detailed e xplanations.  \\n \\nSimilar question detection  \\nSimilar question detection is a natural language processing (NLP) task that involves identifying questions \\nthat are semantically similar or equivalent in meaning. This task is particularly useful in applications such \\nas search engines, community forums, and question -answering systems to improve the user experience by \\ngrouping similar questions together. Here's an overview of similar question detection:  \\n1. Problem Definition : The goal of similar question detection is to determine whether two or more \\nquestions or queries are semantically equivalent or closely related. The task involves comparing \\nthe meaning and intent of different questions.  \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-4_DL.pdf', 'page': 12}, page_content='2. Text Preprocessing : The first step is to preprocess the text, which may include tokenization, \\nlowercasing, and re moving stop words and punctuation to standardize the text data.  \\n3. Feature Extraction : Features are extracted from the text data to represent the questions in a \\nnumerical format suitable for comparison. Common feature representations include:  \\n• Bag of Words (Bo W): A matrix representing the frequency of words in each question.  \\n• Word Embeddings : Dense vector representations of words using techniques like \\nWord2Vec or GloVe.  \\n• TF-IDF (Term Frequency -Inverse Document Frequency) : A numerical representation \\nthat considers  the importance of words in the context of a document or corpus.  \\n4. Similarity Measurement : Once feature representations are obtained; similarity metrics are used \\nto compare the questions. Common similarity metrics include:  \\n• Cosine Similarity : Measures the cos ine of the angle between two vectors, providing a \\nsimilarity score between 0 and 1, with higher scores indicating greater similarity.  \\n• Jaccard Similarity : Measures the size of the intersection of sets divided by the size of the \\nunion of sets.  \\n• Edit Distance (Levenshtein Distance) : Measures the minimum number of character edits \\nrequired to transform one string into another. Lower edit distances indicate higher \\nsimilarity.  \\n5. Thresholding : A similarity threshold is set to determine whether two questions are consid ered \\nsimilar. If the similarity score exceeds this threshold, the questions are classified as similar; \\notherwise, they are considered dissimilar.  \\n6. Machine Learning Models : Machine learning models, such as supervised or unsupervised \\nmodels, can be used to le arn the similarity patterns between questions. Examples of such models \\ninclude Siamese networks, logistic regression, and support vector machines.  \\n7. Training Data : For supervised approaches, a labeled dataset is required, with pairs of questions \\nand their corresponding similarity labels (similar or dissimilar).  \\n8. Evaluation : The performance of similar question detection systems is evaluated using metrics like \\naccuracy, precision, recall, F1 -score, or receiver operating characteristic (ROC) curves. These  \\nmetrics assess the ability of the system to correctly identify similar questions while minimizing \\nfalse positives.  \\n9. Applications : Similar question detection has applications in information retrieval, community \\nforums, customer support chatbots, and questio n-answering systems. It can improve user \\nexperience by suggesting related questions or directing users to existing answers.  \\n10. Challenges : Challenges in similar question detection include handling variations in phrasing, \\nunderstanding the context of the quest ions, and dealing with data sparsity.  '),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-4_DL.pdf', 'page': 13}, page_content=\"Overall, similar question detection is a valuable component of many NLP applications, helping users find \\nrelevant information efficiently and improving the quality of question -answering systems.  \\n \\nDialogue topic trackin g \\nDialogue topic tracking, also known as topic detection or dialogue management, is an essential component \\nin natural language processing (NLP) and human -computer interaction, especially in conversational \\nsystems like chatbots, virtual assistants, and cust omer support systems. Topic tracking involves identifying \\nand maintaining awareness of the current topic or subject of conversation during a dialogue. This helps \\nensure that the system can respond coherently and contextually to user queries or statements. Here's an \\noverview of dialogue topic tracking:  \\n1. Initial Context Setting:  \\n• At the beginning of a conversation, the dialogue system may set an initial context or topic based \\non user input or system prompts.  \\n2. Dialogue State Representation:  \\n• The system maint ains a dialogue state or context representation, which includes information about \\nthe current topic, the conversation history, and any relevant variables or context that affect the \\ndialogue.  \\n3. User Utterance Analysis:  \\n• When the user provides an utterance o r question, the system analyzes it to identify the topic or \\nintent. Various NLP techniques, including intent recognition and named entity recognition, can be \\nused to extract the topic or keywords.  \\n4. Context Updates:  \\n• The system updates the dialogue state to reflect the new topic or intent identified in the user's \\nutterance. This may involve updating a topic variable, storing relevant information, or tracking the \\nstate of an ongoing task or transaction.  \\n5. Context Management:  \\n• The system manages and st ores the context throughout the dialogue, ensuring that it has a complete \\npicture of the conversation's trajectory and the topics covered.  \\n6. Tracking Multiple Topics:  \\n• In more complex dialogues, multiple topics or subtopics may be tracked simultaneously. This \\nrequires maintaining separate context variables for each topic and updating them as the \\nconversation evolves.  \\n \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-4_DL.pdf', 'page': 14}, page_content=\"7. Context Switching:  \\n• When a user explicitly changes the topic or asks a new question, the system switches the current \\nconte xt or topic to address the user's new query or intent.  \\n8. Coherence and Contextual Responses:  \\n• The system generates responses that are coherent with the current topic or context. Responses \\nshould take into account the dialogue history and maintain context t o provide relevant answers or \\ninformation.  \\n9. Contextual Suggestions and Assistance:  \\n• Topic tracking enables the system to provide contextually relevant suggestions, information, or \\nactions that align with the current conversation's topic.  \\n10. Evaluation an d Maintenance:  \\n• The performance of the topic tracking system is evaluated based on its ability to maintain context, \\nidentify topics accurately, and respond coherently. Regular updates and maintenance are often \\nrequired to improve the system's performance.  \\nApplications:  \\n• Dialogue topic tracking is applied in various conversational systems, including chatbots, virtual \\nassistants, customer support systems, and information retrieval systems. It helps ensure that users \\nreceive relevant and context -aware responses during interactions.  \\nEffective topic tracking is essential for creating engaging and user -friendly conversational experiences. It \\nenables more natural and productive interactions in various domains, from customer service to general \\ninformation retrieval.  \\n \\nNeural Summarization  \\nNeural summarization, or neural network -based text summarization, is a natural language processing \\n(NLP) technique that uses neural networks to generate concise and coherent summaries of longer text \\ndocuments or articles. Summarization  is essential for distilling the most important information from text \\nand can be applied in various domains, such as news summarization, document summarization, and \\ncontent recommendation. Here's an overview of neural summarization:  \\n1. Data Preparation:  \\n• Collect and preprocess the text data that you want to summarize. This could be a news article, a \\nresearch paper, a product review, or any other text document.  \\n2. Text Tokenization and Embedding:  \\n• Tokenize the text into sentences and words. Preprocess the te xt by removing stop words, \\npunctuation, and performing other cleaning tasks.  \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-4_DL.pdf', 'page': 15}, page_content=\"• Convert words or subword units into numerical representations using word embeddings (e.g., \\nWord2Vec, GloVe) or subword embeddings (e.g., FastText).  \\n3. Sequence -to-Sequence Model:  \\n• Neural summarization typically employs a sequence -to-sequence model, which is composed of \\ntwo main components: an encoder and a decoder.  \\n• The encoder reads and processes the input text (source text) and encodes it into a fixed -size context \\nvector that captu res the important information.  \\n• The decoder generates a summary by decoding the context vector into a sequence of words that \\nform the summary.  \\n4. Attention Mechanism:  \\n• To improve the quality of summaries, many neural summarization models incorporate attentio n \\nmechanisms. Attention allows the model to focus on specific parts of the input text when \\ngenerating each word in the summary.  \\n5. Training Data:  \\n• For training the neural summarization model, you need a dataset with pairs of source texts and \\nhuman -generated  summaries. These pairs serve as the training examples, allowing the model to \\nlearn to generate coherent and informative summaries.  \\n6. Training:  \\n• Train the model using the source text and target summaries, with a suitable loss function, such as \\nsequence cro ss-entropy or reinforcement learning objectives.  \\n7. Evaluation:  \\n• Evaluate the performance of the summarization model using metrics like ROUGE (Recall -\\nOriented Understudy for Gisting Evaluation), BLEU (Bilingual Evaluation Understudy), or other \\nsummary -speci fic evaluation measures. These metrics assess the quality of the generated \\nsummaries by comparing them to reference summaries.  \\n8. Abstractive vs. Extractive Summarization:  \\n• Neural summarization models can be categorized as abstractive or extractive. Abstrac tive models \\ngenerate summaries in a more creative and human -like manner, whereas extractive models select \\nand rearrange sentences or phrases from the source text to create a summary.  \\n9. Fine -Tuning and Hyperparameter Tuning:  \\n• Fine-tuning and hyperparameter tuning are often necessary to optimize the summarization model's \\nperformance. Techniques such as beam search and diverse decoding strategies may be used to \\nenhance the quality of generated summaries.  \\n \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-4_DL.pdf', 'page': 16}, page_content='10. Applications:  \\n• Neural summarization h as applications in news aggregation, content recommendation, document \\nsummarization, and information retrieval. It can automatically generate concise and informative \\nsummaries from large volumes of text, making it easier for users to access essential infor mation.  \\nNeural summarization has advanced the field of text summarization by providing more context -aware and \\nhuman -like summaries. It allows for the creation of efficient and informative summaries across a range of \\ndomains, improving the accessibility and  readability of complex documents.  \\n '),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-1_DL.pdf', 'page': 0}, page_content=\"Unit -1  \\nFeedforward neural network  \\n \\nA feedforward neural network, also known as a feedforward artificial neural network or simply a \\nfeedforward neural network (FNN), is a type of artificial neural network that's structured in layers, with \\ninformation flowing in one direction, from the input layer to the output layer. It's one of the fundamental \\narchitectures in deep learning and is often used for various tasks such as classification, regression, and \\nfunction approximation.  \\nHere are some key characteris tics and components of feedforward neural networks:  \\n1. Layers : A feedforward neural network typically consists of three types of layers:  \\n• Input Layer : This is the layer where data is fed into the network. Each node in the input \\nlayer represents a feature or in put variable.  \\n• Hidden Layers : These are one or more layers between the input and output layers. Each \\nnode (neuron) in a hidden layer performs a weighted sum of its inputs and applies an \\nactivation function to produce an output. The presence of hidden layers  allows the network \\nto learn complex relationships in the data.  \\n• Output Layer : The output layer produces the final prediction or output of the network. \\nThe number of nodes in the output layer depends on the nature of the task (e.g., binary \\nclassification, m ulti-class classification, regression), and the activation function used in this \\nlayer may vary accordingly.  \\n2. Connections and Weights : Each connection between nodes in adjacent layers has an associated \\nweight. These weights are learned during training to en able the network to make accurate \\npredictions. The weighted sum of inputs is calculated for each neuron, and an activation function \\nis applied to this sum to produce the neuron's output.  \\n3. Activation Functions : Activation functions introduce non -linearity in to the network, allowing it \\nto model complex relationships. Common activation functions include ReLU (Rectified Linear \\nUnit), sigmoid, and tanh. Each neuron in the hidden layers and the output layer typically applies \\nan activation function to its weighted sum of inputs.  \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-1_DL.pdf', 'page': 1}, page_content=\"4. Feedforward Propagation : During the forward pass or feedforward propagation, input data is \\npassed through the network, layer by layer, from the input to the output. The outputs of each layer \\nserve as the inputs to the next layer, and this pr ocess continues until the final prediction is obtained \\nat the output layer.  \\n5. Loss Function : A loss function measures the error or discrepancy between the predicted output \\nand the actual target values. The goal during training is to minimize this loss by adj usting the \\nweights of the network.  \\n6. Backpropagation : After computing the loss, the network uses an optimization algorithm, such as \\ngradient descent or one of its variants, to update the weights in the opposite direction of the \\ngradient. This process is call ed backpropagation. It iteratively adjusts the weights to minimize the \\nloss and improve the network's performance.  \\n7. Training Data : Feedforward neural networks require labeled training data to learn from. The \\nnetwork learns by adjusting its weights based on the training examples, trying to minimize the \\ndifference between its predictions and the actual targets.  \\n8. Hyperparameters : Hyperparameters are settings that are not learned by the network but are set \\nby the user before training. These include the number of hidden layers, the number of neurons in \\neach layer, the learning rate, the choice of activation functions, and others. Finding the right \\nhyperparameters is crucial for achieving good performance.  \\nFeedforward neural networks can be used for a wide range of tasks, including image classification, natural \\nlanguage processing, and many others. However, they are limited in their ability to handle sequential data \\nor capture spatial relationships in data (which tasks like image segmentation require). For these task s, \\nother architectures like recurrent neural networks (RNNs) and convolutional neural networks (CNNs) are \\nmore suitable. Nevertheless, feedforward networks are a fundamental building block in deep learning and \\nserve as the basis for more complex network ar chitectures.  \\nGradient descent and backpropagation  \\nGradient descent and backpropagation are fundamental concepts in training artificial neural networks, \\nincluding feedforward neural networks. They are crucial for adjusting the network's weights to minimize \\nthe prediction error during the training process.  \\n1. Gradient Descent : \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-1_DL.pdf', 'page': 2}, page_content=\"Gradient descent is an optimization algorithm used to minimize a cost or loss function by adjusting the \\nparameters (weights and biases) of a neural network. Here's a brief overview of how gradient descent \\nworks:  \\n• Initialization : Initially, the network's parameters (weights and biases) are set to random \\nvalues or small values close to zero.  \\n• Forward Pass : The input data is passed forward through the network, layer by layer, to \\nproduce a prediction.  \\n• Loss Calculation : A loss function (also known as a cost function or objective function) is \\nused to measure how far off the predictions are from the actual target values. The goal is \\nto minimize this loss.  \\n• Backward Pass (Backpropagation) : The co re of gradient descent is the calculation of \\ngradients (derivatives) of the loss with respect to the network's parameters. This is done by \\napplying the chain rule of calculus backward through the network layers. It involves \\ncomputing how much a small chang e in each parameter would affect the loss.  \\n• Parameter Update : The gradients tell us the direction and magnitude of the steepest \\nincrease in the loss function. Gradient descent updates the parameters in the opposite \\ndirection of the gradient to decrease the loss. The update rule for each parameter is \\ntypically:  \\nEx. :      new_parameter = old_parameter - learning_rate * gradient  \\nHere, the learning rate is a hyperparameter that controls the size of each step taken during parameter \\nupdates.  \\n• Iterative Process : Steps 3 to 5 are repeated for a specified number of iterations (epochs) \\nor until the loss converges to a satisfactory minimum value.  \\n• Convergence : Gradient descent continues until the loss stops decreasing significantly, \\nindicating that the network has learn ed the optimal parameters or until a predefined \\nstopping criterion is met.  \\n2. Backpropagation : \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-1_DL.pdf', 'page': 3}, page_content=\"Backpropagation is the specific algorithm used to compute gradients efficiently in a neural network during \\nthe backward pass. It's a systematic way to calculate the  gradients of the loss with respect to each parameter \\nin the network. Here's a simplified overview of backpropagation:  \\n• Forward Pass : As mentioned earlier, the input data is passed forward through the network \\nto produce predictions.  \\n• Loss Calculation : The lo ss is calculated based on the predictions and the actual target \\nvalues.  \\n• Backward Pass (Backpropagation) : This is where backpropagation comes into play. It \\nconsists of the following steps:  \\na. Compute the gradient of the loss with respect to the output layer 's activations.  \\nb. Propagate this gradient backward through the network, layer by layer, by applying the chain rule to \\ncompute gradients at each layer.  \\nc. Accumulate the gradients of the weights and biases at each layer.  \\n• Parameter Update : Once the gradient s have been computed, gradient descent (or a similar \\noptimization algorithm) is used to update the network's parameters, as described in the \\ngradient descent section.  \\n• Repeat : The forward and backward passes, along with parameter updates, are repeated for \\nmultiple iterations until the network's performance improves or the loss converges.  \\nBackpropagation allows neural networks to efficiently learn from data by updating their weights in the \\ndirection that reduces the prediction error. It's a key algorithm in t raining deep neural networks and is used \\nextensively in various machine learning tasks.  \\nUnit saturation  \\nUnit saturation, in the context of artificial neural networks, refers to a situation where the neurons (units) \\nin a neural network layer become saturate d, meaning that their outputs are pushed to the extreme ends of \\ntheir activation function's range. This phenomenon can have significant implications for the network's \\ntraining and performance.  \\nHere are the key points about unit saturation:  \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-1_DL.pdf', 'page': 4}, page_content='1. Activation Functions : Unit saturation is closely related to the choice of activation functions. \\nCommon activation functions like the sigmoid and tanh functions have S -shaped curves that \\nsaturate when their inputs become extremely large (positive or negativ e). For sigmoid and tanh \\nfunctions, saturation occurs when inputs are far from zero.  \\n2. Vanishing Gradient : Unit saturation can lead to the vanishing gradient problem during \\nbackpropagation. When the activations of neurons are pushed to the extreme values (cl ose to 0 or \\n1 for sigmoid or close to -1 or 1 for tanh), the gradient of the activation function becomes very \\nclose to zero. This means that during backpropagation, the gradient signal that is used to update \\nthe weights of the network becomes extremely sma ll, making it difficult for the network to learn \\neffectively. This can slow down or hinder the training process, especially in deep networks.  \\n3. Exploding Gradient : Conversely, unit saturation can also lead to the exploding gradient problem. \\nIf activations become extremely large (far from zero), the gradient can become very large as well. \\nThis can result in weight updates that are too large, causing the network to diverge during training.  \\n4. Mitigation : To address unit saturation, researchers and pr actitioners have explored alternative \\nactivation functions that do not suffer from saturation issues. One popular choice is the Rectified \\nLinear Unit (ReLU) activation function, which is linear for positive inputs and avoids saturation \\nfor positive values.  Leaky ReLU and Parametric ReLU (PReLU) are variations of ReLU that \\nmitigate the dying ReLU problem (where some units never activate).  \\n5. Batch Normalization : Techniques like batch normalization have been introduced to mitigate \\nsaturation issues by normalizin g the inputs to each layer, helping to keep activations in a healthier \\nrange during training.  \\n6. Initialization : Proper weight initialization methods, such as He initialization or Xavier \\ninitialization, can also help mitigate saturation issues by setting init ial weights in a way that \\nprevents early saturation during training.  \\nIn summary, unit saturation occurs when the activations of neurons in a neural network layer are pushed \\nto the extreme values, leading to problems like vanishing or exploding gradients. C areful selection of \\nactivation functions, weight initialization methods, and techniques like batch normalization can help \\nmitigate unit saturation and improve the training and performance of neural networks.  \\nVanishing gradient problem and ways to mitigate it \\nThe vanishing gradient problem is a challenge that occurs during the training of deep neural networks, \\nparticularly in feedforward neural networks with many layers. It affects the convergence and learning of '),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-1_DL.pdf', 'page': 5}, page_content=\"the network and arises from the way gradients  are propagated backward through the network during the \\ntraining process.  \\nHere's a brief explanation of the vanishing gradient problem and some ways to mitigate it:  \\nVanishing Gradient Problem : The vanishing gradient problem occurs when gradients (partial d erivatives \\nof the loss function with respect to network parameters) become extremely small as they are propagated \\nbackward through the layers of a deep neural network. This phenomenon is particularly problematic when \\nusing activation functions that squash their inputs into a small range, such as the sigmoid or hyperbolic \\ntangent (tanh) functions.  \\nWhen the gradients are very small, the updates to the weights during the optimization process (e.g., using \\ngradient descent) become tiny, effectively slowing down or halting the learning process for the early layers \\nof the network. As a result, the network has difficulty learning meaningful representations and capturing \\nlong-range dependencies in the data.  \\nWays to Mitigate the Vanishing Gradient Problem : \\n1. Use Activat ion Functions with Non -Vanishing Gradients : \\n• Replace activation functions like sigmoid or tanh with activation functions that have non -\\nvanishing gradients, such as Rectified Linear Units (ReLU). ReLU activation functions are \\ncomputationally efficient and do  not suffer from the vanishing gradient problem for \\npositive inputs.  \\n2. Weight Initialization : \\n• Initialize the network weights appropriately. Careful weight initialization methods, such as \\nHe initialization for ReLU -based networks or Xavier/Glorot initializati on for sigmoid and \\ntanh networks, can help alleviate the vanishing gradient problem by setting a good starting \\npoint for training.  \\n3. Batch Normalization : \\n• Apply batch normalization layers within the network. Batch normalization normalizes the \\nactivations of e ach layer during training, helping to maintain a consistent range of values \\nand mitigating the vanishing gradient problem.  \\n4. Skip Connections (Residual Networks) : \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-1_DL.pdf', 'page': 6}, page_content='• Use skip connections or residual connections in deep architectures. In residual networks \\n(ResNe ts), for example, shortcut connections allow gradients to flow more easily through \\nthe network by skipping one or more layers. This helps in training very deep networks \\neffectively.  \\n5. Gradient Clipping : \\n• Implement gradient clipping to prevent exploding gradients. While not a direct solution to \\nthe vanishing gradient problem, gradient clipping limits the magnitude of gradients during \\ntraining, preventing them from becoming too large, which can destabilize t he training \\nprocess.  \\n6. Recurrent Architectures : \\n• For sequential data, consider using recurrent neural networks (RNNs) or Long Short -Term \\nMemory (LSTM) networks. These architectures are designed to capture sequential \\ndependencies and tend to be less affected b y the vanishing gradient problem in such \\ncontexts.  \\n7. Gradient -Based Optimizers : \\n• Experiment with advanced optimization algorithms that adaptively adjust the learning \\nrates, such as Adam or RMSprop. These optimizers can help address gradient -related issues \\nto some extent.  \\n8. Gradient -Boosted Architectures : \\n• Consider architectures that are specifically designed to address the vanishing gradient \\nproblem, such as Gated Recurrent Units (GRUs) and LSTMs for sequential data or \\narchitectures like the Transformer for natur al language processing tasks.  \\nIn practice, the choice of activation functions, weight initialization methods, and architectural design \\ndecisions can significantly impact the occurrence and severity of the vanishing gradient problem. Careful \\nexperimentation  and tuning are often required to find the best combination of techniques to mitigate this \\nissue for a specific deep learning task.  \\nRelU Heuristics for avoiding bad local minima  \\n '),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-1_DL.pdf', 'page': 7}, page_content=\"ReLU (Rectified Linear Unit) is a commonly used activation function in neural  networks that has some \\nheuristics associated with it, which can help avoid the issue of getting stuck in bad local minima during \\nthe training of deep neural networks. The problem of getting trapped in bad local minima arises because \\nthe loss landscape of deep networks is highly non -convex, meaning there are many hills and valleys in the \\nloss surface, and finding the global minimum (the best set of weights for the network) can be challenging.  \\nHere's a brief explanation of the ReLU heuristics for avoiding ba d local minima:  \\n1. Non-Saturating Activation : ReLU is non -saturating, meaning that it does not saturate (flatten) \\nfor large positive input values. This property helps prevent the vanishing gradient problem, which \\noccurs when gradients become too small during backpropagation, making it difficult for the \\nnetwork to learn. Since ReLU does not squash its inputs, it allows gradients to flow more freely \\nthrough the network, making it easier for the model to learn.  \\n2. Sparsity : ReLU introduces sparsity into the network by zeroing out negative values. This sparsity \\nencourages the network to learn sparse representations of the data, which can be helpful in \\npreventing overfitting. Sparse representations capture the most essential features of the data and \\ncan generalize bett er to unseen examples.  \\n3. Random Initialization : The He initialization (He initialization or He et al. initialization) is a \\ncommon weight initialization technique used with ReLU activation. It initializes the weights of \\nneurons with small random values drawn from a normal distribution with mean 0 and standard \\ndeviation based on the number of input units. This initialization strategy helps prevent neurons \\nfrom starting with identical weights, which can lead to symmetrical updates during training and \\nmake it mor e likely for the network to get stuck in local minima.  \\n4. Batch Normalization : Batch normalization is a technique that can be used in conjunction with \\nReLU to further stabilize and speed up the training of deep networks. It normalizes the inputs to \\neach layer , making the optimization landscape smoother and reducing the risk of getting stuck in \\npoor local minima.  \\n5. Adaptive Learning Rates : Techniques like adaptive learning rate schedulers, such as Adam or \\nRMSprop, adjust the learning rate during training. These a daptive methods help prevent the \\nnetwork from taking excessively large steps in the parameter space, which can cause it to overshoot \\nand get stuck in local minima.  \\nWhile ReLU and its associated heuristics can help mitigate the vanishing gradient problem an d improve \\ntraining in deep networks, it's important to note that they do not completely eliminate the risk of getting \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-1_DL.pdf', 'page': 8}, page_content='stuck in local minima. The choice of architecture, weight initialization, and hyperparameters also plays a \\nsignificant role in training de ep neural networks effectively. Researchers continue to explore and develop \\ntechniques to address optimization challenges in deep learning, but ReLU and its associated heuristics \\nhave been instrumental in the success of deep neural networks in various appl ications.  \\nHeuristics for faster training  \\n \\nHeuristics for faster training in machine learning and deep learning refer to practical guidelines and \\nstrategies that can help speed up the training process of neural networks and improve the efficiency of the \\ntraining algorithm. These heuristics aim to r educe training time while still achieving good or even better \\nmodel performance. Here are some common heuristics for faster training:  \\n1. Data Preprocessing : \\n• Normalization : Scale and center input data to have zero mean and unit variance. This can \\nhelp gradients propagate more smoothly during training.  \\n• Data Augmentation : Generate additional training examples by applying random \\ntransformations (e.g., rotation, translation, cropping) to the input data. Data augmentation \\nincreases the effective size of the training dataset without collecting more data.  \\n2. Batch Size : \\n• Use larger batch sizes when training on GPUs or TPUs. Larger batches can exploit \\nparallelism more efficiently and often result in faster convergence. However, very large \\nbatch sizes may require tun ing the learning rate.  \\n3. Learning Rate Schedule : \\n• Implement a learning rate schedule that reduces the learning rate over time. This can help \\nthe model converge faster initially when larger steps are beneficial and then refine the \\nweights more gradually as it approaches a minimum.  \\n4. Early Stopping : \\n• Monitor a validation metric (e.g., validation loss or accuracy) during training and stop \\ntraining when these metric stops  improving. Early stopping prevents overfitting and saves \\ntraining time.  \\n5. Gradient Clipping : '),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-1_DL.pdf', 'page': 9}, page_content='• Clip gradients during training to prevent exploding gradients. This involves setting a \\nthreshold value, and if gradients exceed this threshold, they are scaled down. Gradient \\nclipping can stabilize training.  \\n6. Transfer Learning : \\n• Utilize pre -trained models and fin e-tune them for your specific task. Transfer learning \\nleverages the knowledge gained from training on a large dataset and can significantly \\nreduce the training time for your task.  \\n7. Reduce Model Complexity : \\n• If your model is over -parameterized, consider reduc ing its complexity by decreasing the \\nnumber of layers or neurons. A simpler model may train faster and generalize better.  \\n8. Parallelization : \\n• Distribute training across multiple GPUs or machines to take advantage of parallel \\nprocessing. Data parallelism and m odel parallelism techniques can be used for this purpose.  \\n9. Hardware Acceleration : \\n• Use specialized hardware like GPUs or TPUs for training, as they are designed to accelerate \\ndeep learning workloads and can significantly speed up training compared to using o nly \\nCPUs.  \\n10. Caching and Memorization : \\n• Cache or memorize  intermediate results, especially during data preprocessing or feature \\nextraction, to avoid redundant computations during training.  \\n11. Sparse Data Representations : \\n• Use sparse data representations when deali ng with high -dimensional data, like text or \\ncategorical features, to reduce memory and computation requirements.  \\n12. Regularization Techniques : \\n• Apply regularization techniques like dropout, L1 regularization, or L2 regularization to \\nprevent overfitting, which can lead to faster convergence.  \\n13. Optimizers : '),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-1_DL.pdf', 'page': 10}, page_content='• Experiment with different optimization algorithms (e.g., Adam, RMSprop, SGD) and their \\nhyperparameters to find the one that converges faster for your specific problem.  \\n14. Parallel Data Loading : \\n• Use efficient data loading techniques like parallel data loading to minimize data loading \\nbottlenecks, especially when working with large datasets.  \\nThese heuristics are not one -size-fits-all and may require experimentation and tuning based on the specific \\nproblem and dataset you are working with. Effective combinations of these heuristics can lead to \\nsignificantly faster training times while maintaining or even improving model performance.  \\n \\nNesterov Accelerated Gradient Descent  \\n \\nNesterov Accelerated Gradient Descent, often referred to as NAG or Nesterov Momentum, is an \\noptimization algorithm used in training neural networks and other machine learning models. It is an \\nextension of the standard momentum -based gradient descent algori thm that aims to improve convergence \\nspeed and stability.  \\nHere\\'s a brief explanation of Nesterov Accelerated Gradient Descent:  \\n1. Momentum -Based Gradient Descent : \\n• In standard momentum -based gradient descent, a moving average of past gradients is used \\nto updat e the model\\'s weights.  \\n• The update step is governed by two components: the current gradient and the \"momentum \\nterm,\" which is a weighted average of past gradients.  \\n• The momentum term helps the optimization process by dampening oscillations in the \\nweight upda tes and accelerating convergence in the relevant direction.  \\n2. Nesterov Accelerated Gradient Descent : \\n• Nesterov Momentum goes one step further by modifying how the gradient is computed \\nduring weight updates.  \\n• Instead of calculating the gradient at the current p osition in weight space, Nesterov \\nMomentum calculates it slightly ahead in the direction of the current momentum.  '),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-1_DL.pdf', 'page': 11}, page_content='• It computes a \"lookahead\" gradient by first updating the weights using the momentum term \\nand then calculating the gradient at the new, lookahe ad position.  \\n• The weight update is then based on this lookahead gradient.  \\n3. Advantages of Nesterov Accelerated Gradient Descent : \\n• Nesterov Momentum is known to converge faster than standard momentum -based gradient \\ndescent in many cases. This is because it has the ability to \"anticipate\" the direction in \\nwhich the gradient is changing and make more informed updates.  \\n• It can reduce oscillations and overshooting during training, leading to more stable \\nconvergence.  \\n• Nesterov Momentum can help the optimization process escape shallow local minima more \\nefficiently.  \\n•  \\nMathematically, the update step in Nesterov Accelerated Gradient Descent is as follows:  \\nvelocity = momentum * velocity - learning_rate * gradient_at_lookahead weights = weights + velocity  \\nWhere:  \\n• velocity  is the moving average of past gradients (momentum term).  \\n• learning_rate  is the step size, determining how large the updates should be.  \\n• gradient_at_lookahead  is the gradient calculated at the lookahead position (ahead of the current \\nweights) . \\n• weights  are the model\\'s parameters (weights and biases) being updated.  \\nIn summary, Nesterov Accelerated Gradient Descent enhances traditional momentum -based optimization \\nby looking ahead before computing the gradient update. This can lead to faster and m ore stable \\nconvergence, making it a popular choice for optimizing neural networks and other machine learning \\nmodels.  '),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-1_DL.pdf', 'page': 12}, page_content=' \\nRegularization and dropout  \\n \\nRegularization and dropout are techniques used in deep learning to prevent overfitting, which occurs when \\na neural network performs well on the training data but poorly on unseen or validation data. Both \\ntechniques aim to improve the generalization of a neural network, making it more robust and capable of \\nbetter handling new, unseen data.  \\n1. Regularization : \\nRegulariz ation is a set of techniques that add a penalty term to the loss function during training. This \\npenalty discourages the model from learning overly complex patterns that may fit the training data \\nperfectly but are unlikely to generalize well. There are two common types of regularization techniques:  \\n• L1 and L2 Regularization : These are also known as Lasso and Ridge regularization, \\nrespectively. They add a penalty term to the loss function based on the magnitude of the \\nmodel\\'s weights.  \\n• L1 regularization encoura ges sparse weight values by adding the absolute values of \\nthe weights to the loss.  \\n• L2 regularization encourages small weight values by adding the squares of the \\nweights to the loss.  \\nThe amount of regularization is controlled by a hyperparameter, often denoted as lambda (λ), which \\ndetermines the strength of the penalty. By adjusting this hyperparameter, you can control the trade -off \\nbetween fitting the training data well and preventing overfitting.  \\n2. Dropout : \\nDropout is a specific reg ularization technique that operates during training and is particularly effective for \\ndeep neural networks. During each training iteration, dropout randomly \"drops out\" (i.e., sets to zero) a \\nfraction of neurons in a layer, including their connections. Thi s means that for each forward and backward \\npass, a different set of neurons is active.  \\nDropout helps prevent co -adaptation of neurons, which can occur when neurons in a layer rely too heavily \\non specific other neurons. By randomly dropping out neurons, dro pout encourages the network to learn \\nmore robust features and reduces the risk of overfitting.  '),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-1_DL.pdf', 'page': 13}, page_content='Typically, dropout is applied to the hidden layers of a neural network, and the dropout rate is a \\nhyperparameter that determines the probability of dropping out each neuron (common values are around \\n0.2 to 0.5). During inference or when making predictions, dropout is usually turned off, and the entire \\nnetwork is used.  \\nIn summary, regularization techniques like L1 and L2 regularization add penalties to the loss function \\nbased on the magnitude of the weights to prevent overfitting. Dropout, on the other hand, randomly \\ndeactivates neurons during training to encourage the n etwork to learn more robust features and reduce \\noverfitting. These techniques are essential tools for improving the generalization and performance of \\nneural networks on unseen data.  \\nConvolutional Neural Networks  \\n \\nPeople are getting more fascinated with Art ificial Intelligence, Machine Learning, and Deep Learning in \\nthe current world. These fields have been using a wide range of techniques and algorithms to give humans \\nthe best results. If you specifically consider deep learning, it uses neural networks to m imic the human \\nbrain. Several kinds of neural networks are used in a wide range of applications of deep learning like \\nimage processing, image segmentation, self -driving cars, etc. One such popular neural network is CNN \\nwhich stands for Convolutional Neural  Network.  \\nWhat is CNN?  \\nConvolutional Neural Networks (CNN, or ConvNet) are a type of multi -layer neural network that is meant \\nto discern visual patterns from pixel images. In CNN, ‘convolution’ is referred to as the mathematical \\nfunction. It’s a type of li near operation in which you can multiply two functions to create a third function \\nthat expresses how one function’s shape can be changed by the other. In simple terms, two images that are \\nrepresented in the form of two matrices, are multiplied to provide a n output that is used to extract \\ninformation from the image. CNN is similar to other neural networks, but because they use a sequence of \\nconvolutional layers, they add a layer of complexity to the equation. CNN cannot function without \\nconvolutional layers.  In a variety of computer vision tasks, CNN artificial neural networks have risen to \\nthe top. It has picked people’s interest in a variety of fields.  \\nA convolutional neural network is made up of numerous layers, such as convolution layers, pooling layers, \\nand fully connected layers, and it uses a backpropagation algorithm to learn spatial hierarchies of data \\nautomatically and adaptively. You will learn more about these terms in the following section.  \\nTypical CNN Architecture  \\n '),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-1_DL.pdf', 'page': 14}, page_content=' \\nThe ConvNet’s job is to compr ess the images into a format that is easier to process while preserving \\nelements that are important for obtaining a decent prediction. This is critical for designing an architecture \\nthat is capable of learning features while also being scalable to large da tasets.  \\nA convolutional neural network, ConvNets in short has three layers which are its building blocks, let’s \\nhave a look:  \\nConvolutional Layer  (CONV):   \\nThese layers apply convolution operations to input data. Convolutional filters slide over the input, learning \\nto detect features like edges, textures, and patterns. Multiple filters create feature maps.  \\nThey are the foundation of CNN, and they are in charge of executing convolution operations. The \\nKernel/Filter is the component in this layer that performs the convolution operation (matrix). Until the \\ncomplete image is scanned, the kernel makes horizontal and vertical adjustments dependent on the stride \\nrate. The kernel is less in size than a picture, but it has more depth. This means that if the im age has three \\n(RGB) channels, the kernel height and width will be modest spatially, but the depth will span all three.  \\n \\n \\n'),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-1_DL.pdf', 'page': 15}, page_content='Other than convolution, there is another important part of convolutional layers, known as the Non -linear \\nactivation function. The outputs of the linear operations like convolution are passed through a non -linear \\nactivation function. Although smooth nonlinear functions such as the sigmoid or hyperbolic tangent (tanh) \\nfunction were formerly utilized because they are mathematical repres entations of biological neuron \\nactions. The rectified linear unit (ReLU) is now the most commonly used non -linear activation function. \\nf(x)\\u2009=\\u2009max(0,\\u2009x)  \\nPooling Layer  (POOL):  \\n Pooling layers reduce spatial dimensions while retaining important information. M ax pooling and average \\npooling are common operations. They make the network more robust to translations and scale variations.  \\nThis layer is in charge of reducing dimensionality. It aids in reducing the amount of computing power \\nrequired to process the dat a. Pooling can be divided into two types: maximum pooling and average \\npooling. The maximum value from the area covered by the kernel on the image is returned by max pooling. \\nThe average of all the values in the part of the image covered by the kernel is re turned by average pooling.  \\n \\n \\n \\nFully Connected Layer  (FC):  \\nThe fully connected layer (FC) works with a flattened input, which means that each input is coupled to \\nevery neuron. After that, the flattened vector is sent via a few additional FC layers, where the mathematical \\nfunctional operations are normally performed. The classification procedure gets started at this point. FC \\nlayers are frequently found near the end of CNN architectures if they are present.  \\n'),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-1_DL.pdf', 'page': 16}, page_content=' \\n \\nAlong with the above layers, there are some add itional terms that are part of a CNN architecture.  \\nActivation Function:   \\nThe last fully connected layer’s activation function is frequently distinct from the others. Each activity \\nnecessitates the selection of an appropriate activation function. The softma x function, which normalizes \\noutput real values from the last fully connected layer to target class probabilities, where each value ranges \\nbetween 0 and 1 and all values total to 1, is an activation function used in the multiclass classification \\nproblem.  \\nDropout Layers:  \\nThe Dropout layer is a mask that nullifies some neurons’ contributions to the following layer while leaving \\nall others unchanged. A Dropout layer can be applied to the input vector, nullifying some of its properties; \\nhowever, it can also be  applied to a hidden layer, nullifying some hidden neurons. Dropout layers are \\ncritical in CNN training because they prevent the training data from overfitting. If they aren’t there, the \\nfirst batch of training data has a disproportionately large impact on  learning. As a result, learning of traits \\nthat occur only in later samples or batches would be prevented:  \\nNow you have got a good understanding of the building blocks of CNN, let’s have a look to some of the \\npopular CNN architecture.  \\nCNN Architectures:  \\n• LeNet -5: One of the earliest CNNs designed by Yann LeCun, used for handwritten digit \\nrecognition.  \\n• AlexNet : Introduced by Alex Krizhevsky, it was a breakthrough in deep learning and popularized \\nCNNs. It won the ImageNet competition in 2012.  \\n• VGGNet : Known for its uniform architecture with small 3x3 convolutional filters. Variants like \\nVGG16 and VGG19 are widely used.  \\n'),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-1_DL.pdf', 'page': 17}, page_content='• GoogLeNet (Inception) : Developed by Google, it uses inception modules with multiple filter sizes \\nto capture features at different  scales.  \\n• ResNet (Residual Network) : Introduced residual connections that enable training of very deep \\nnetworks. It won the ImageNet competition in 2015 and is the basis for many subsequent \\narchitectures.  \\n1. LeNet Architecture  \\n \\nThe LeNet architecture is simple and modest making it ideal for teaching the fundamentals of CNNs. It \\ncan even run on the CPU (if your system lacks a decent GPU), making it an excellent “first CNN.” It’s \\none of the first and most extensively used CNN designs, and it ’s been used to successfully recognize \\nhandwritten digits. The LeNet -5 CNN architecture has seven layers. Three convolutional layers, two \\nsubsampling layers, and two fully linked layers make up the layer composition.  \\n \\n2. AlexNet Architecture  \\n \\nAlexNet’s archi tecture was extremely similar to LeNet’s. It was the first convolutional network to employ \\nthe graphics processing unit (GPU) to improve performance. Convolutional filters and a non -linear \\nactivation function termed ReLU are used in each convolutional laye r (Rectified Linear Unit). Max \\npooling is done using the pooling layers. Due to the presence of fully connected layers, the input size is \\nfixed. The AlexNet architecture was created with large -scale image datasets in mind, and it produced state -\\nof-the-art results when it was first released. It has 60 million characteristics in all . \\n'),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-1_DL.pdf', 'page': 18}, page_content=' \\n3. VGGNet Architecture  \\n \\nWhile prior AlexNet derivatives focused on smaller window sizes and strides in the first convolutional \\nlayer, VGG takes a different approach to CNN. It takes input as a 224×224 pixel RGB image. To keep the \\ninput image size consistent for the ImageNet competition, the authors clipped out the middle 224×224 \\npatch in each image. The receptive field of the convolutional layers in VGG is quite tiny. The convol ution \\nstride is set at 1 pixel in order to preserve spatial resolution after convolution. VGG contains three \\ncompletely connected layers, the first two of which each have 4096 channels and the third of which has \\n1000 channels, one for each class. Due to it s adaptability for a variety of tasks, including object detection, \\nthe VGG CNN model is computationally economical and serves as a good baseline for many applications \\nin computer vision.  \\n \\n \\n \\nAdvantages of CNN Architecture  \\nFollowing are some of the advantag es of a Convolutional Neural Network:  \\n• CNN is computationally efficient.  \\n'),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-1_DL.pdf', 'page': 19}, page_content=\"• It performs parameter sharing and uses special convolution and pooling algorithms. CNN models \\nmay now run on any device, making them globally appealing.  \\n• It finds the relevant features without the need for human intervention.  \\n• It can be utilized in a variety of industries to execute key tasks such as facial recognition, document \\nanalysis, climate comprehension, image recognition, and item identification, among others.  \\n• By feeding your data on each level and tuning the CNN a little for a specific purpose, you can \\nextract valuable features from an already trained CNN with its taught weights.  \\n \\nNormalization Techniques:  \\n• Batch Normalization (BatchNorm) : Normalizes activations within a batch,  helping stabilize \\ntraining and reduce the impact of vanishing/exploding gradients.  \\n• Layer Normalization (LayerNorm) : Similar to BatchNorm but normalizes across the entire \\nlayer.  \\n• Group Normalization (GroupNorm) : Splits channels into groups and normalizes wi thin each \\ngroup. It's a compromise between BatchNorm and LayerNorm.  \\n \\nSequence Modeling:  \\n• CNNs are primarily designed for grid -like data such as images. However, they can be adapted for \\nsequence data through techniques like:  \\n• 1D Convolutions : Used for sequenc e data, where the convolution operation moves along \\na single dimension.  \\n• TimeDistributed Layers : Apply a layer to each time step of a sequence independently.  \\n• Recurrent CNNs (RCNNs) : Combine convolutional layers with recurrent layers for \\nsequential data proc essing.  \\nApplications:  \\n• Image Classification : Identifying objects or classes within images.  \\n• Object Detection : Locating and classifying objects within an image.  \\n• Image Segmentation : Assigning labels to individual pixels or regions within an image.  \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-1_DL.pdf', 'page': 20}, page_content='• Face Recogni tion: Recognizing faces in images or video streams.  \\n• Natural Language Processing (NLP) : CNNs can be used for text classification, sentiment \\nanalysis, and document classification when combined with techniques like word embeddings.  \\n• Medical Imaging : Diagnosing diseases from medical images such as X -rays and MRIs.  \\n• Autonomous Vehicles : Detecting objects, pedestrians, and lane markings for self -driving cars.  \\n• Video Analysis : Analyzing video feeds for surveillance, activity recognition, and more.  \\n• Artificia l Intelligence (AI) Art : Generating art and images using neural style transfer with CNNs.  \\nCNNs have demonstrated remarkable performance in these applications, and their ability to automatically \\nlearn hierarchical features from data makes them a cornerstone  of modern machine learning and computer \\nvision. Researchers and engineers continue to develop and refine CNN architectures to tackle new \\nchallenges and improve performance across various domains.  \\n '),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-2_DL.pdf', 'page': 0}, page_content='Unit -2 \\nRecurrent Neural Network (RNN)  \\nA recurrent neural network ( RNN ) is a kind of artificial neural network mainly used in  speech \\nrecognition  and natural language processing  (NLP). RNN is used in deep learning and in the \\ndevelopment of models that imitate the activity of neurons in the human  brain . \\nRecurrent Networks are designed to  recognize patterns  in sequences of data, such as  text, genomes, \\nhandwriting, the spoken word,  and numerical  time series data emanating from sensors, stock markets, \\nand g overnment agencies.  \\nA recurrent neural network looks similar to a traditional neural network except that a memory -state is \\nadded to the neurons. The computation is to include a simple memory.  \\nThe recurrent neural network is a type of deep learning -oriented  algorithm, which follows a sequential \\napproach. In neural networks, we always assume that each input and output is dependent on all other \\nlayers. These types of neural networks are called recurrent because they sequentially perform \\nmathematical computatio ns. \\n \\nThe recurrent network first performs the conversion of independent activations into dependent ones. It \\nalso assigns the same weight and bias to all the layers, which reduces the complexity of RNN of \\nparameters. And it provides a standard platform for  memorization of the previous outputs by providing \\nprevious output as an input to the next layer.  \\nThese three layers having the same weights and bias, combine into a single recurrent unit.  \\n \\nFor calculating the current state - \\nht =f(h t-1, Xt) \\n'),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-2_DL.pdf', 'page': 1}, page_content='Where  \\nht= current -state  \\nHt-1= previous -state  \\nXt= input state  \\nTo apply the activation function tanh, we have - \\nht = tanh (W hhht-1+ W xhXt) \\nWhere:  \\nWhh = weight of recurrent neuron and  \\n \\nWxh = weight of the input neuron  \\nThe formula for calculating output:  \\nYt = W hyht \\n \\nApplication of RNN  \\nRNN has multiple uses when it comes to predicting the future. In the financial industry, RNN can help \\npredict stock prices or the sign of the stock market direction (i.e.,  positive  or negative ). \\nRNN is used for an autonomous car as it ca n avoid a car accident by anticipating the route of the vehicle.  \\nRNN is widely used in  image captioning, text analysis, machine translation,  and sentiment \\nanalysis . For example,  one should use a movie review to understanding the feeling the spectator \\nperceived after  watching the movie . Automating this task is very useful when the movie company can \\nnot have more time to review, consolidate, label, and analyze the reviews. The machine can do the job \\nwith a higher level of accuracy.  \\n \\nFollowing a re the application of RNN:  \\n1. Machine Translation  \\nWe make use of Recurrent Neural Networks in the translation engines to translate the text from one to \\nanother language. They do this with the combination of other models like  LSTM  (Long short -term \\nmemory) s. '),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-2_DL.pdf', 'page': 2}, page_content=' \\n2. Speech Recognition  \\nRecurrent Neural Networks has replaced the traditional speech recognition models that made use of \\nHidden Markov Models. These Recurrent Neural Networks, along with LSTMs, are better poised at \\nclassifying speeches and converting the m into text without loss of context.  \\n \\n \\n \\n3. Sentiment Analysis  \\nWe make use of sentiment analysis to positivity, negativity, or the neutrality of the sentence. Therefore, \\nRNNs are most adept at handling data sequentially to find sentiments of the sentence.  \\n \\n4. Automatic Image Tagger  \\n'),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-2_DL.pdf', 'page': 3}, page_content=\"RNNs, in conjunction with convolutional neural networks, can detect the images and provide their \\ndescriptions in the form of tags. For example, a picture of a fox jumping over the fence is better explained \\nappropriatel y using RNNs.  \\n \\nLimitations of RNN  \\nRNN is supposed to carry the information in time. However, it is quite challenging to propagate all this \\ninformation when the time step is too long. When a network has too many deep layers, it becomes \\nuntrainable. This problem is called: vanishing gradient problem.  \\nIf we remember, the neural network updates the weight use of the gradient descent algorithm. The gradient \\ngrows smaller when the network progress down to lower layers.  \\nThe gradient stays cons tant, meaning there is no space for improvement. The model learns from a change \\nin its gradient; this change affects the network's output. If the difference in the gradient is too small (i.e., \\nthe weight change a little), the system can't learn anything an d so the output. Therefore, a system facing a \\nvanishing gradient problem cannot converge towards the right solution.  \\n \\nLong short -term memory (LSTM)   \\nLong Short - Term Memory (LSTM) networks are a modified version of recurrent neural networks, which \\nmakes it  easier to remember past data in memory.  \\nLong short -term memory (LSTM) is an artificial recurrent neural network (RNN) architecture used in the \\nfield of deep learning. It was proposed in 1997 by  Sepp Hochreiter  and Jurgen schmidhuber . Unlike \\nstandard feed -forward neural networks, LSTM has feedback connections. It can process not only single \\ndata points (such as images) but also entire sequences of data (such as speech or video).  \\nFor example,  LSTM is an application to tasks such as unsegmented,  connected handwriting \\nrecognition,  or speech recognition . \\nA general  LSTM  unit is composed of a cell, an input gate, an output gate, and a forget gate. The cell \\nremembers values over arbitrary time intervals, and three gates regulate the flow of information  into and \\n\"),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-2_DL.pdf', 'page': 4}, page_content='out of the cell. LSTM is well -suited to classify, process, and predict the time series given of unknown \\nduration.  \\n \\n1. Input gate - It discover which value from input should be used to modify the \\nmemory.  Sigmoid  function decides which values to let through 0 or 1. And  tanh function \\ngives weightage to the values which are passed, deciding their level of importance ranging \\nfrom  -1 to 1.  \\n \\n \\n2. Forget gate - It discover the details to be discarded from the block. A sigmoid function \\ndecides it. It looks at the previous state  (ht-1) and the content input (Xt) and outputs a \\nnumber between 0(omit this) and 1(keep this) for each number in the cell state  Ct-1. \\n \\n \\n3. Output gate - The input and the memory of the block are used to decide the output. Sigmoid \\nfunction decides which values to let through 0 or 1. And  tanh  function decides which values \\nto let through 0, 1. And tanh function gives weightage to the values which are passed, \\ndeciding their level of importance ranging from  -1 to 1  and multiplied with a n output \\nof sigmoid . \\n \\n \\n'),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-2_DL.pdf', 'page': 5}, page_content=' \\nIt represents a full RNN cell that takes the current input of the sequence xi, and outputs the current \\nhidden state, hi, passing this to the next RNN cell for our input sequence. The inside of an LSTM cell is \\na lot more complicate d than a traditional RNN cell, while the conventional RNN cell has a single \\n\"internal layer\" acting on the current state (ht -1) and input (xt).  \\nLSTM vs RNN  \\nConsider, you have the task of modifying certain information in a calendar. To do this, an RNN completely \\nchanges the existing data by applying a function. Whereas, LSTM makes small modifications to the data \\nby simple addition or multiplication that flow through cell states. This is how LSTM forgets and \\nremembers things selectively, which makes it a n improvement over RNNs.  \\nNow consider, you want to process data with periodic patterns in it, such as predicting the sales of colored \\npowder that peak at the time of Holi in India. A good strategy is to look back at the sales records of the \\nprevious year. So, you need to know what data needs to be forgotten and what needs to be stored for later \\nreference. Else, you need to have a really good memory.  Recurrent neural networks  seem to be doing a \\ngood job at this, theoretically. However, they have two downsides, exploding gradient, and vanishing \\ngradient, that make them redundant.  \\nHere, LSTM introduces memory units, called cell states, to solve this problem. The designed cells may be \\nseen as differentiable memory.  \\nLSTM Applications  \\nLSTM networks find useful applications in the following areas:  \\n• Language modeling  \\n• Machine translation  \\n• Handwriting recognition  \\n'),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-2_DL.pdf', 'page': 6}, page_content='• Image captioning  \\n• Image ge neration using attention models  \\n• Question answering  \\n• Video -to-text conversion  \\n• Polymorphic music modeling  \\n• Speech synthesis  \\n• Protein secondary structure prediction  \\nThis list does give an idea about the areas in which LSTM is employed but not how exactly it is u sed. \\nLet’s understand the types of sequence learning problems that LSTM networks are capable of addressing.  \\n \\nLSTM neural networks are capable of solving numerous tasks that are not solvable by previous learning \\nalgorithms like RNNs. Long -term temporal depe ndencies can be captured effectively by LSTM, without \\nsuffering many optimization hurdles. This is used to address the high -end problems.  \\n \\nGated Recurrent Unit Networks  \\n• In sequence modeling techniques, the Gated Recurrent Unit is the newest entrant after R NN and LSTM, \\nhence it offers an improvement over the other two.  \\n• Understand the working of GRU and how it is different from LSTM  \\nIntroduction  \\nGRU or Gated recurrent unit is an advancement of the standard RNN i.e recurrent neural network. It was \\nintroduced by  Kyunghyun Cho et a l in the year 2014.  \\nGRUs are very similar to Long Short Term Memory(LSTM). Just like LSTM, GRU uses gates to control \\nthe flow of information. They are relatively new as compared to LSTM. This is the reason they offer some \\nimprovement over LSTM and have simpler architecture . \\n '),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-2_DL.pdf', 'page': 7}, page_content=' \\n \\nAnother Interesting thing about   GRU is that, unlike LSTM, it does not have a separate cell state (Ct). It \\nonly has a hidden state(Ht). Due to the simpler architecture, GRUs are faster to train.  \\nThe architecture of Gated Recurrent Unit  \\nNow lets’ underst and how GRU works. Here we have a GRU cell which more or less similar to an LSTM \\ncell or RNN cell.  \\n \\nAt each timestamp t, it takes an input Xt  and the hidden state Ht -1 from the previous timestamp t -1. Later \\nit outputs a new hidden state Ht which again passed to the next timestamp.  \\nNow there are primarily two gates in a GRU as opposed to three gates in an LSTM cell. The first gate is \\nthe Reset g ate and the other one is the update gate.  \\nReset Gate (Short term memory)  \\nThe Reset Gate is responsible for the short -term memory of the network i.e the hidden state (Ht). Here is \\nthe equation of the Reset gate.  \\n'),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-2_DL.pdf', 'page': 8}, page_content=' \\nIf you remember from the LSTM gate equation it is very similar to that. The value of  rt will range from 0 \\nto 1 because of the sigmoid function. Here Ur and Wr are weight matrices for the reset gate.  \\nUpdate Gate (Long Term memory)  \\nSimilarly, we have an Update gate for long -term memory and th e equation of the gate is shown below.  \\n \\nThe only difference is of weight metrics i.e Uu and Wu.   \\nHow GRU Works  \\nNow let’s see the functioning of these gates. To find the Hidden state Ht in GRU, it follows a two -step \\nprocess. The first step is to generate w hat is known as the candidate hidden state. As shown below  \\nCandidate Hidden State  \\n \\nIt takes in the input and the hidden state from the previous timestamp t -1 which is multiplied by the reset \\ngate output rt. Later passed this entire information to the tanh  function, the resultant value is the \\ncandidate’s hidden state.  \\n \\nThe most important part of this equation is how we are using the value of the reset gate to control how \\nmuch influence the previous hidden state can have on the candidate state.  \\n'),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-2_DL.pdf', 'page': 9}, page_content='If the value  of rt is equal to 1 then it means the entire information from the previous hidden state Ht -1 is \\nbeing considered. Likewise, if the value of rt is 0 then that means the information from the previous hidden \\nstate is completely ignored.  \\nHidden state  \\nOnce we have the candidate state, it is used to generate the current hidden state Ht. It is where the Update \\ngate comes into the picture. Now, this is a very interesting equation, instead of using a separate gate like \\nin LSTM in GRU we use a single update gate to control both the historical information which is Ht -1 as \\nwell as the new information which comes from the candidate state.  \\n \\nNow assume the value of ut  is around 0 then the first term in the equation will vanish which means the \\nnew hidden state will not have much information from the previous hidden state. On the other hand, the \\nsecond part becomes almost one that essentially means the hidden state at th e current timestamp will \\nconsist of the information from the candidate state only.  \\n \\nSimilarly, if the value of ut is on the second term will become entirely 0 and the current hidden state will \\nentirely depend on the first term i.e the information from the  hidden state at the previous timestamp t -1. \\n \\nHence we can conclude that the value of ut is very critical in this equation and it can range from 0 to 1.  \\n  \\n \\n \\n'),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-2_DL.pdf', 'page': 10}, page_content=\" \\nEncoder -Decoder architectures  \\nEncoder -Decoder architectures are a class of neural network architectures designed for various tasks that \\ninvolve sequence -to-sequence transformations, where an input sequence is processed and transformed into \\nan output sequence. These architectures consist of two main components: an encoder and a decoder. Here's \\nan overview of how they work:  \\n \\n1. Encoder : \\n• The encoder is responsible for processing and encoding the input sequence into a fixed -\\nlength context or hidden representation. This context vector aims to capture the essential \\ninformation from the input sequence.  \\n• Commonly used encoders include recurrent neural networks (RNNs), Long Short -Term \\nMemory (LSTM) networks, Gated Recurrent Units (GRUs), or more recently, transformer -\\nbased encoders like the one used in the Transformer architecture.  \\n• The encoder processes the input sequence step by step and generates hidden states at each \\ntime step. The final hidden state or a combination of hidden states is used as the context \\nvector.  \\n2. Context Vector : \\n• The context vector produced by the encoder serves as a summary of the input sequence. It \\nshould contain relevant information required for the subsequent decoding step.  \\n• The method for generating the context vector can vary. In some cases, it may be the last \\nhidden state of the encoder, while in others, it could be a weighted combination of all \\nhidden states (attention mechanism).  \\n3. Decoder : \\n• The decoder takes the context vector and generates the output sequence step by step.  \\n• Like the encoder, the decoder can also be implemented using RNNs, LSTMs, GRUs, or \\ntransformers.  \\n• During dec oding, the context vector and previously generated output elements (if any) are \\nused as inputs to predict the next element in the output sequence.  \\n\"),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-2_DL.pdf', 'page': 11}, page_content=\"• The decoder generates the output sequence one element at a time, conditioning each \\nprediction on the previous  elements generated.  \\nEncoder -Decoder architectures are versatile and have been applied to a wide range of natural language \\nprocessing tasks and beyond, including:  \\n• Machine Translation : Translating text from one language to another.  \\n• Image Captioning : Generat ing textual descriptions of images.  \\n• Text Summarization : Creating concise summaries of longer texts.  \\n• Speech Recognition : Converting spoken language into text.  \\n• Chatbots and Conversational AI : Generating human -like responses in chatbot applications.  \\n• Video Cap tioning : Creating textual descriptions of video content.  \\n• Mathematical Problem Solving : Solving mathematical problems by generating step -by-step \\nsolutions.  \\n• Time Series Forecasting : Predicting future values in time series data.  \\nEncoder -Decoder architectures have been enhanced over time with improvements like attention \\nmechanisms and transformer architectures, leading to state -of-the-art performance in many sequence -to-\\nsequence tasks. These architectures have played a significant role in advancin g the capabilities of neural \\nnetworks for handling sequential data.  \\nIntroduction to Simple DNN Platform for Deep Learning  \\nA Simple Deep Neural Network (DNN) Platform for Deep Learning is a software framework or platform \\ndesigned to facilitate the development, training, and deployment of deep learning models, particularly \\ndeep neural networks. These platforms aim to simplify the process of building and experimenting with \\nneural networks while providing tools and resources for effective model trainin g and deployment. Here's \\na brief introduction to the key aspects of such a platform:  \\n1. Model Building and Architecture : \\n• The platform provides tools and APIs to define and customize the architecture of deep \\nneural networks. Users can specify the number of lay ers, types of layers (e.g., dense, \\nconvolutional, recurrent), activation functions, and connections between layers to create \\ntheir neural network models.  \\n \\n2. Data Preparation : \\n• Data is a critical component of deep learning. The platform offers utilities for lo ading, \\npreprocessing, and augmenting data to prepare it for training. This may include data \\nnormalization, data splitting into training and validation sets, and handling data in various \\nformats (e.g., images, text, time series).  \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-2_DL.pdf', 'page': 12}, page_content=\"3. Training and Optimization : \\n• The platform includes training algorithms and optimization techniques to train neural \\nnetworks on the provided data. Users can specify hyperparameters like learning rates, batch \\nsizes, and epochs to control the training process. Additionally, it may suppor t various \\noptimization algorithms (e.g., stochastic gradient descent, Adam) and learning rate \\nschedules.  \\n4. Monitoring and Visualization : \\n• During training, the platform typically offers monitoring tools to track metrics such as loss \\nand accuracy. Visualization  tools may provide graphs and charts to help users understand \\nthe model's performance and identify potential issues.  \\n5. Hyperparameter Tuning : \\n• Many platforms offer functionality for hyperparameter tuning, allowing users to \\nautomatically search for the best co mbination of hyperparameters to optimize model \\nperformance.  \\n6. Model Evaluation and Metrics : \\n• After training, the platform provides tools to evaluate the trained model's performance on \\nvalidation or test data. Common evaluation metrics include accuracy, precis ion, recall, F1 \\nscore, and more, depending on the specific problem.  \\n7. Deployment Options : \\n• Some platforms offer deployment options to take trained models into production. This may \\ninvolve exporting models in standard formats (e.g., TensorFlow SavedModel, ONNX ) and \\ndeploying them on cloud services, edge devices, or web applications.  \\n8. Community and Support : \\n• A strong user community and support resources, such as documentation, tutorials, and \\nforums, can be essential for users to learn and troubleshoot issues with the platform.  \\n9. Integration with Libraries and Frameworks : \\n• Many DNN platforms are built on top of popular deep learning libraries and frameworks \\nlike TensorFlow, PyTorch, or Keras. They provide abstractions and additional features to \\nsimplify the development  process.  \\n10. Scalability and Performance : \\n• Depending on the use case, the platform may support distributed training and GPU \\nacceleration to handle large datasets and computationally intensive tasks efficiently.  \\nIn summary, a Simple DNN Platform for Deep Learning aims to streamline the process of designing, \\ntraining, and deploying deep neural networks by offering a user -friendly interface, data handling \\ncapabilities, training and optimization tools, and options fo r model deployment. These platforms play a \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-2_DL.pdf', 'page': 13}, page_content='crucial role in democratizing deep learning and making it accessible to a wider audience of developers \\nand researchers.  \\nDeep Learning Software Libraries  \\nDeep learning software libraries are frameworks and tools th at provide a collection of pre -implemented \\nalgorithms, functions, and APIs for building, training, and deploying deep neural networks (DNNs). These \\nlibraries serve as the foundation for developing and experimenting with complex neural network \\narchitectures , making it easier for researchers, data scientists, and developers to work on deep learning \\nprojects. Here are some key aspects of deep learning software libraries:  \\n1. Abstraction of Complexity : \\n• Deep learning libraries abstract the underlying complexity of n eural network \\nimplementation. Instead of manually coding neural network layers and operations, users \\ncan work with high -level APIs that simplify the process.  \\n2. Neural Network Components : \\n• Libraries provide a wide range of neural network components, including layers (e.g., \\nconvolutional layers, recurrent layers), activation functions, loss functions, optimizers, and \\nmore. Users can assemble these components to create custom network architectures.  \\n3. Support for Popular Frameworks : \\n• Many deep learning libraries are built on top of popular deep learning frameworks like \\nTensorFlow, PyTorch, and Keras. This allows users to leverage the capabilities of these \\nframeworks while benefiting from additional features provided by the library.  \\n4. Efficient Computation : \\n• Libraries are optimized for efficient computation, often using GPU acceleration to speed \\nup training and inference processes. This makes it feasible to work with large datasets and \\ncomplex models.  \\n5. Automatic Differentiation : \\n• Automatic di fferentiation is a key feature of deep learning libraries. It enables the \\ncomputation of gradients for backpropagation during training, which is essential for \\noptimizing neural networks.  \\n6. Pre-trained Models : \\n• Many libraries offer pre -trained models and model  architectures for common tasks, such \\nas image classification, object detection, and natural language processing. Users can fine -\\ntune these models for specific applications, saving significant time and computational \\nresources.  \\n7. Flexibility and Customization : '),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-2_DL.pdf', 'page': 14}, page_content=\"• Users have the flexibility to create custom neural network architectures and experiment \\nwith various hyperparameters to fine -tune model performance.  \\n8. Visualization and Debugging Tools : \\n• Libraries often include visualization tools for monitoring training pr ogress, examining \\nmodel architectures, and debugging issues in the network.  \\n9. Community and Ecosystem : \\n• Deep learning libraries benefit from active communities that contribute to documentation, \\ntutorials, and code examples. This fosters knowledge sharing and helps users overcome \\nchallenges in their projects.  \\n10. Scalability : \\n• Some libraries support distributed computing for training on clusters of machines, enabling \\nscalability for large -scale deep learning tasks.  \\nPopular deep learning libraries include:  \\n• TensorFlow : Developed by Google, TensorFlow is an open -source library known for its flexibility \\nand scalability. It offers TensorFlow Keras for a high -level API and TensorFlow.js for JavaScript -\\nbased deep learning.  \\n• PyTorch : Developed by Facebook's AI Resea rch lab, PyTorch is appreciated for its dynamic \\ncomputational graph and is widely used in research. It has a strong community and supports GPU \\nacceleration.  \\n• Keras : Originally an independent library, Keras has become part of TensorFlow's high -level API. \\nIt is known for its simplicity and ease of use, making it a great choice for beginners.  \\n• Caffe : A deep learning framework developed by the Berkeley Vision and Learning Center (BVLC) \\nand used for image -related tasks.  \\n• MXNet : A flexible deep learning framework wi th support for multiple programming languages, \\nincluding Python and Scala.  \\n• Theano : An early deep learning library that contributed to the development of modern libraries \\nlike TensorFlow and PyTorch.  \\nThese libraries empower researchers and practitioners to work on a wide range of deep learning \\napplications, from computer vision and natural language processing to reinforcement learning and beyond. \\nThe choice of library often depends on specific project requirements and personal preferences.  \\n \\nDeep unsupervised  learning  \\nDeep unsupervised learning is a subset of machine learning where the objective is to extract meaningful \\npatterns, representations, or structures from unlabeled data. Unlike supervised learning, which relies on \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-2_DL.pdf', 'page': 15}, page_content=\"labeled examples to make predictions  or classifications, unsupervised learning works with data that has \\nno predefined target labels. Instead, it aims to discover inherent patterns or information hidden within the \\ndata. Here's a brief explanation of deep unsupervised learning:  \\n1. Objective : \\n• The primary goal of deep unsupervised learning is to learn useful representations of data \\nwithout explicit guidance or labels. These learned representations can capture essential \\nfeatures or structures in the data.  \\n2. Data Types : \\n• Deep unsupervised learning can be  applied to various types of data, including images, text, \\naudio, and numerical data. Each type of data may require different architectures and \\ntechniques for unsupervised learning.  \\n3. Methods : \\n• Autoencoders: Autoencoders are a common type of neural network us ed for unsupervised \\nlearning. They consist of an encoder network that maps input data to a lower -dimensional \\nrepresentation (encoding) and a decoder network that reconstructs the input data from this \\nencoding.  \\n• Restricted Boltzmann Machines (RBMs): RBMs are  probabilistic models used for \\nunsupervised learning. They model the probability distribution over visible and hidden \\nunits and can be stacked to create deep architectures.  \\n• Generative Adversarial Networks (GANs): GANs consist of two neural networks, a \\ngene rator and a discriminator, which are trained adversarially. The generator tries to create \\ndata samples that are indistinguishable from real data, while the discriminator aims to \\ndistinguish between real and generated samples.  \\n• Variational Autoencoders (VAEs ): VAEs combine the concepts of autoencoders and \\nprobabilistic modeling. They learn a probabilistic mapping from data to a latent space and \\ncan generate new data samples by sampling from this latent space.  \\n4. Applications : \\n• Deep unsupervised learning has a wide range of applications, including:  \\n• Dimensionality Reduction: Learning compact representations of high -dimensional \\ndata.  \\n• Clustering: Grouping similar data points together without predefined clusters.  \\n• Anomaly Detection: Identifying rare or abnormal insta nces in a dataset.  \\n• Data Denoising: Removing noise from data while preserving essential information.  \\n• Representation Learning: Learning informative representations for downstream \\nsupervised tasks.  \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-2_DL.pdf', 'page': 16}, page_content='• Image Generation: Creating new images that resemble the train ing data.  \\n• Language Modeling: Learning representations for words and sentences.  \\n5. Challenges : \\n• Deep unsupervised learning can be challenging because it relies solely on the intrinsic \\nstructure of data. The quality of learned representations depends on the choi ce of \\narchitecture, hyperparameters, and the amount of unlabeled data available.  \\n6. Advancements : \\n• Recent advancements in deep unsupervised learning include the use of deep generative \\nmodels, such as variational autoencoders and generative adversarial networks , which have \\nled to significant progress in generating realistic data samples and learning high -quality \\nrepresentations.  \\nIn summary, deep unsupervised learning is a branch of machine learning focused on discovering valuable \\npatterns and representations in unlabeled data. It is a crucial area of research with numerous practical \\napplications and has contributed to advancements in artificial intelligence and data analysis.  \\n \\nAutoencoders  \\nAutoencoders are a class of neural network architectures used in unsupervised learning and dimensionality \\nreduction. They are primarily designed to learn efficient representations of data by encoding it into a \\ncompressed form and then decoding it to reconstruct the original input. Autoencoders have applications \\nin vario us fields, including image denoising, feature learning, and anomaly detection. Here\\'s a brief \\nexplanation of autoencoders:  \\n1. Encoder : The encoder is the first part of an autoencoder and is responsible for mapping the input \\ndata into a lower -dimensional repre sentation. This lower -dimensional representation is often called \\nthe \"latent space\" or \"encoding.\" The encoder typically consists of multiple layers, with each layer \\ntransforming the input data into a more compact and abstract representation.  \\n2. Bottleneck La yer: In the middle of the autoencoder, there is a bottleneck layer or the latent \\nrepresentation. This layer contains a compact representation of the input data, which captures the \\nmost essential features and patterns.  \\n3. Decoder : The decoder is the second par t of the autoencoder and aims to reconstruct the original \\ninput data from the encoded representation. Like the encoder, the decoder consists of multiple \\nlayers. It attempts to generate an output that is as close as possible to the input data, typically usi ng \\nsymmetric layers to the encoder.  \\n4. Loss Function : To train the autoencoder, a loss function is defined, which quantifies the difference \\nbetween the input data and the reconstructed output. Common loss functions include mean squared \\nerror (MSE) for continuous data or binary cross -entropy for binary data. The goal of training is to \\nminimize this loss.  '),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-2_DL.pdf', 'page': 17}, page_content='5. Training : Autoencoders are trained using unsupervised learning, meaning they do not require \\nlabeled data. During training, the autoencoder learns to cap ture the essential features and patterns \\nin the data, as the encoder learns to extract meaningful information, and the decoder learns to \\nreconstruct the data from that information.  \\n6. Dimensionality Reduction : One practical application of autoencoders is dime nsionality \\nreduction. By reducing the dimensionality of the latent space, autoencoders can capture the most \\nimportant features of high -dimensional data while discarding less relevant information. This can \\nbe useful for data visualization, feature extractio n, and reducing the computational cost of \\nsubsequent tasks.  \\n7. Variational Autoencoders (VAEs) : VAEs are a variation of autoencoders that introduce a \\nprobabilistic approach to the encoding and decoding process. They are known for their ability to \\ngenerate new  data samples similar to the training data and have applications in generative \\nmodeling.  \\nAutoencoders have found applications in various fields, including image compression, denoising, anomaly \\ndetection, and even natural language processing. They serve as a fundamental building block for more \\ncomplex neural network architectures and can be adapted and extended for various specialized tasks.  \\n \\nVariational Autoencoders (VAEs)  \\nVariational Autoencoders (VAEs) are a type of generative model in the field of deep l earning. They are \\ndesigned to learn and generate data, often used for tasks like image generation, data compression, and \\neven data denoising. VAEs are particularly useful when dealing with high -dimensional data, such as \\nimages or sequences.  \\nHere\\'s a brief explanation of Variational Autoencoders:  \\n1. Autoencoder Architecture : \\n• VAEs are built upon the architecture of autoencoders, which consists of an encoder and a \\ndecoder.  \\n• The encoder takes an input data point and maps it to a lower -dimensional representation \\ncalled the \"latent space\" or \"latent variables.\" This process is called \"encoding.\"  \\n• The decoder then takes this lower -dimensional representation and tries to reconstruct the \\noriginal input data. This process is called \"decoding.\"  \\n2. Variational Component : \\n• What s ets VAEs apart from traditional autoencoders is the incorporation of probabilistic \\nmodeling. Instead of encoding data into a fixed point in the latent space, VAEs encode data \\ninto probability distributions over the latent space.  '),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-2_DL.pdf', 'page': 18}, page_content='• Specifically, VAEs use Gaus sian distributions to model the relationships between the input \\ndata and the latent variables. This means that for each data point, the encoder outputs a \\nmean and variance that define a Gaussian distribution in the latent space.  \\n3. Sampling from Latent Space : \\n• During the training process, VAEs introduce a critical step called \"sampling.\" Given the \\nmean and variance from the encoder\\'s output, VAEs sample a point from the corresponding \\nGaussian distribution in the latent space.  \\n• This stochastic sampling introduces  randomness, which is crucial for generating diverse \\nand novel data points during the decoding process.  \\n4. Objective Function : \\n• VAEs use a specific objective function during training, called the \"variational lower bound\" \\nor \"evidence lower bound\" (ELBO).  \\n• The ELBO encourages the encoder to produce Gaussian distributions in the latent space \\nthat are both close to the true posterior distributions and spread out enough to encourage \\ndiversity in generated samples.  \\n• Minimizing the reconstruction loss (how well th e decoder can reconstruct the original \\ninput) is another component of the ELBO.  \\n5. Generative Process : \\n• Once trained, VAEs can be used for data generation. To generate new data points, you \\nsample from the latent space (typically from a standard Gaussian distri bution) and pass this \\nsampled point through the decoder to produce new data samples.  \\n6. Applications : \\n• VAEs find applications in various domains, including image generation, data compression, \\ndenoising, anomaly detection, and more.  \\n• They are especially popular in generative modeling tasks where you want to create new \\ndata samples that resemble the training data distribution.  \\nIn summary, Variational Autoencoders combine elements of autoencoders with probabilistic modeling to \\ngenerate data. They are trained to enc ode data into probabilistic representations in the latent space, \\nallowing for the generation of new, similar data points. VAEs have found success in a wide range of \\ngenerative modeling applications and are a fundamental concept in deep learning.  \\n \\nGenerativ e Adversarial Networks (GANs ) \\nAdversarial Generative Networks, often referred to as Generative Adversarial Networks (GANs), are a \\nclass of deep learning models that consist of two neural networks, the generator and the discriminator, \\nwhich are trained toge ther through a competitive process. GANs were introduced by Ian Goodfellow and '),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-2_DL.pdf', 'page': 19}, page_content='his colleagues in 2014 and have since become a powerful framework for generating synthetic data, images, \\nand content. Here\\'s a brief explanation of how GANs work:  \\n1. Generator : \\n• The generator is a neural network that takes random noise as input and attempts to generate \\ndata that is indistinguishable from real data.  \\n• It typically consists of multiple layers of transposed convolutional or deconvolutional \\nlayers followed by activation fu nctions (e.g., ReLU) to create increasingly complex and \\ndetailed data representations.  \\n• The generator starts with random noise and progressively refines its output to produce data \\nthat becomes more realistic as training progresses.  \\n2. Discriminator : \\n• The discri minator, often called the critic in some variations, is another neural network that \\nevaluates the authenticity of a given piece of data.  \\n• It takes both real data samples and generated data samples as input and tries to distinguish \\nbetween them. The goal is to correctly classify real data as \"real\" and generated data as \\n\"fake.\"  \\n• The discriminator is trained to improve its ability to differentiate between real and fake \\ndata.  \\n3. Training Process : \\n• GANs are trained in a competitive manner. The generator and discriminator are trained \\nsimultaneously but have opposing objectives.  \\n• During training, the generator aims to produce data that is increasingly difficult for the \\ndiscriminator to distinguish from real data.  \\n• The discriminator, on the other hand, aims to bec ome better at distinguishing real from fake \\ndata.  \\n• This adversarial process continues iteratively until the generator generates data that is \\nnearly indistinguishable from real data, and the discriminator can\\'t reliably tell the \\ndifference.  \\n4. Loss Functions : \\n• GANs use loss functions to quantify the performance of the generator and discriminator.  \\n• The generator\\'s loss decreases as it becomes better at fooling the discriminator, while the \\ndiscriminator\\'s loss decreases as it becomes better at distinguishing real f rom fake data.  \\n• Common loss functions used in GANs include binary cross -entropy loss and Wasserstein \\nloss. '),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-2_DL.pdf', 'page': 20}, page_content=\"5. Applications : \\n• GANs have a wide range of applications, including image generation, style transfer, data \\naugmentation, super -resolution, text -to-image s ynthesis, and more.  \\n• They are also used for generating realistic deepfake videos and have raised ethical and \\nprivacy concerns.  \\n6. Variations and Improvements : \\n• Since their inception, GANs have seen numerous variations and improvements, including \\nconditional GAN s (CGANs), deep convolutional GANs (DCGANs), and progressive \\nGANs (PGANs), among others. These variations address specific challenges and enhance \\nGAN performance in different tasks.  \\nIn summary, GANs are a powerful class of deep learning models that excel a t generating data that is \\nvirtually indistinguishable from real data. They leverage the competitive interplay between a generator \\nand discriminator to achieve this, making them valuable tools for various applications in computer vision, \\nnatural language pr ocessing, and generative tasks.  \\nAuto -encoder and DBM  Attention and memory models  \\nAutoencoder : \\n• An autoencoder is a type of neural network used for unsupervised learning and dimensionality \\nreduction.  \\n• It consists of an encoder network that compresses input da ta into a lower -dimensional \\nrepresentation (encoding), and a decoder network that attempts to reconstruct the original data \\nfrom this encoding.  \\n• Autoencoders are commonly used for tasks like data denoising, anomaly detection, and feature \\nlearning.  \\nDeep Bolt zmann Machine (DBM) : \\n• A Deep Boltzmann Machine is a type of generative neural network model.  \\n• It's composed of multiple layers of stochastic binary units (visible and hidden units) and employs \\nenergy -based modeling.  \\n• DBMs are used for modeling complex probability distributions and are capable of capturing deep \\nhierarchical representations.  \\n• Training DBMs is computationally intensive and often involves techniques like contrastive \\ndivergence.  \\nAttention Models : \\n• Attention models are a class of neural network  architectures that focus on relevant parts of input \\ndata when making predictions.  \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-2_DL.pdf', 'page': 21}, page_content=\"• They have been widely used in natural language processing tasks, such as machine translation and \\ntext summarization.  \\n• Attention mechanisms allow models to weigh the importanc e of different parts of the input \\nsequence, which is particularly helpful when dealing with long sequences.  \\nMemory Models : \\n• Memory models in the context of deep learning refer to architectures that incorporate external \\nmemory components.  \\n• These models have t he ability to read from and write to memory, which can help them store and \\nretrieve information over longer sequences.  \\n• Memory -augmented neural networks, like the Neural Turing Machine (NTM) and Differentiable \\nNeural Computer (DNC), are examples of models w ith memory components. They have shown \\npromise in tasks that require complex reasoning and sequential processing.  \\nIn summary, autoencoders are used for data compression and feature learning, DBMs are generative \\nmodels capable of capturing complex probabili ty distributions, attention models help focus on important \\ninformation in sequences, and memory models incorporate external memory for tasks involving longer \\nsequences and complex reasoning. Each of these models has found applications in different areas of  deep \\nlearning and machine learning.  \\nDynamic Memory Networks (DMNs ) \\nDynamic Memory Networks (DMNs) are a type of neural network architecture designed for question -\\nanswering and reasoning tasks, particularly in the context of natural language understanding.  DMNs were \\nintroduced to address the limitations of traditional neural networks in handling complex, multi -step \\nreasoning and inference tasks. Here's a brief overview of Dynamic Memory Networks:  \\n1. Memory Network : At the core of a DMN is a memory network, whi ch is designed to store and \\nretrieve information efficiently. The memory network typically consists of an external memory \\nmatrix that can be read from and written to. Each row in the matrix corresponds to a piece of \\ninformation.  \\n2. Episodic Memory : DMNs inclu de an episodic memory component, which allows the network to \\nread and write to the memory matrix in an iterative manner. This episodic memory mechanism is \\ncrucial for handling sequential and multi -step reasoning tasks.  \\n3. Input Representation : The input to a DMN usually includes a sequence of words or symbols \\nrepresenting the context or passage of text, a question, and sometimes additional information. \\nThese inputs are encoded into vector representations, often using recurrent neural networks \\n(RNNs) or attenti on mechanisms.  \\n4. Attention Mechanism : DMNs incorporate attention mechanisms to focus on relevant information \\nwithin the context or memory matrix. Attention weights are computed to emphasize important \\nelements in the memory based on the current question or context.  \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/Unit-2_DL.pdf', 'page': 22}, page_content=\"5. Episodic Memory Updating : During the reasoning process, a DMN repeatedly interacts with its \\nepisodic memory. It reads from the memory to gather relevant information, updates its internal \\nstate, and writes back to the memory with the updated context. This process is performed over \\nmultiple iterations to accumulate evidence and make a final prediction.  \\n6. Answer Generation : After multiple iterations of reading, reasoning, and updating the episodic \\nmemory, a DMN generates an answer or predi ction based on the accumulated information.  \\n7. Training : DMNs are trained using supervised learning with labeled question -answering pairs. \\nDuring training, the network learns to update its memory and internal state iteratively to minimize \\nthe loss between its  predicted answers and the ground truth answers.  \\n8. Applications : DMNs have been applied to various natural language understanding tasks, including \\nreading comprehension, question -answering, and text -based reasoning. They are particularly \\nuseful for tasks tha t require the model to perform multi -step reasoning over textual information.  \\nIn summary, Dynamic Memory Networks are designed to perform complex reasoning and question -\\nanswering tasks by iteratively interacting with an external memory matrix. They use att ention mechanisms \\nand episodic memory to capture relevant information from the input context and produce accurate answers. \\nDMNs have been successful in various natural language processing applications and continue to be an \\narea of research interest for enh ancing deep learning models' reasoning abilities.  \\n \\n \\n \\n \\n \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-3_DL.pdf', 'page': 0}, page_content='Unit -3  \\nImage segmentation  \\nImage segmentation is a crucial computer vision task that involves dividing an image into distinct \\nregions or segments based on certain criteria, such as object boundaries or semantic content. Deep \\nlearning has significantly advanced the field of image segmentation, enabling more accurate and \\nefficient solutions. Here are some applications of deep learning in image segmentation:  \\n1. Medical Image Segmentation:  \\n• Deep learning models are extensively used in medical imag e analysis for segmenting \\nstructures or abnormalities within medical images, including MRI scans, CT scans, and \\nX-rays. Applications include tumor detection, organ segmentation, and brain lesion \\nidentification.  \\n2. Semantic Segmentation:  \\n• In semantic segmentati on, each pixel in an image is assigned a class label to represent the \\nobject or region it belongs to. Deep neural networks, especially Fully Convolutional \\nNetworks (FCNs), have achieved state -of-the-art performance in tasks like scene \\nunderstanding, autono mous navigation, and robotics.  \\n3. Object Instance Segmentation:  \\n• Object instance segmentation goes beyond semantic segmentation by distinguishing \\nindividual instances of objects. Deep learning models such as Mask R -CNN and PANet \\nare used in applications like a utonomous vehicles to precisely identify and delineate \\nmultiple objects.  \\n4. Industrial Quality Control:  \\n• Deep learning -based image segmentation is employed in manufacturing to inspect \\nproducts for defects or inconsistencies. It ensures that products meet quali ty standards \\nand helps reduce defects in the production process.  \\n5. Satellite and Aerial Image Analysis:  \\n• Deep learning techniques assist in segmenting and classifying objects and land cover in \\nsatellite and aerial imagery. This is vital for applications such as urban planning, \\nagriculture, and environmental monitoring.  \\n6. Natural Scene Understanding:  \\n• Deep learning models for image segmentation are used in natural scene understanding to \\nidentify and segment various elements, such as roads, buildings, vegetation, a nd water \\nbodies. This information is valuable for geographic information systems (GIS) and urban \\nplanning.  \\n '),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-3_DL.pdf', 'page': 1}, page_content=\" \\n7. Interactive Image Editing:  \\n• Deep learning -based image segmentation tools are integrated into image editing software \\nto enable precise and automated object selection for tasks like background removal, \\nimage manipulation, and special effects.  \\n8. Autonomous Robotics:  \\n• Robots and drones leverage deep learning -powered image segmentation for navigation, \\nobstacle avoidance, and object interaction. It allows robo ts to perceive their environment \\naccurately.  \\n9. Agriculture and Crop Monitoring:  \\n• Image segmentation helps in monitoring and managing agricultural fields. It can identify \\nand classify crops, pests, and diseases, enabling precision agriculture practices and yie ld \\noptimization.  \\n10. Biological Image Analysis:  \\n• Deep learning is used for segmenting and analyzing biological images, such as cellular \\nstructures, tissue samples, and microscopy images. This aids in medical research and drug \\ndiscovery.  \\n11. Augmented Reality (AR):  \\n• AR applications use image segmentation to detect objects and surfaces in the real world, \\nallowing virtual objects to be overlaid seamlessly onto the user's view.  \\n12. Security and Surveillance:  \\n• In security and surveillance systems, image segmentation help s identify and track objects \\nor people of interest in video feeds, enhancing security monitoring.  \\nDeep learning has revolutionized image segmentation by enabling the development of highly accurate \\nand efficient models. These models have diverse application s across industries, improving automation, \\naccuracy, and decision -making in a wide range of tasks.  \\n \\nObject detection  \\nObject detection is one of the most important and widely applied tasks in computer vision, and deep \\nlearning has significantly advanced the accuracy and efficiency of object detection systems. Here are \\nsome key applications of deep learning in object detection:  \\n1. Autonomous Vehicles:  \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-3_DL.pdf', 'page': 2}, page_content=\"• Object detection is critical in autonomous vehicles (self -driving cars) for identifying and \\ntracking  objects in the vehicle's surroundings. This includes detecting pedestrians, other \\nvehicles, traffic signs, and obstacles to ensure safe navigation.  \\n2. Surveillance and Security:  \\n• Deep learning -based object detection is used in surveillance systems to monitor and \\nrecognize suspicious activities, track individuals, and identify security threats at airports, \\npublic spaces, and buildings.  \\n3. Retail and Inventory Management:  \\n• Retail stores employ object detection to monitor inventory levels, track products on \\nshelves, and prevent theft. It can also be used for cashier -less checkout systems, where \\nitems are automatically detected and billed as customers leave the store.  \\n4. Healthcare:  \\n• Object detection assists in medical image analysis by identifying and locating \\nabnormaliti es in X -rays, MRIs, and CT scans. It's used in diagnosing diseases, detecting \\ntumors, and monitoring patient health.  \\n5. Industrial Automation:  \\n• In manufacturing and industrial settings, object detection ensures quality control by \\nidentifying defects in product s and inspecting machinery components. It helps automate \\nprocesses and reduce errors.  \\n6. Agriculture:  \\n• Object detection is applied in precision agriculture to monitor crop health, detect diseases, \\nand optimize yield. Drones equipped with object detection techn ology can survey large \\nagricultural fields efficiently.  \\n7. Drones and Aerial Imagery:  \\n• Drones use object detection for various applications, including search and rescue \\nmissions, monitoring wildlife populations, and assessing disaster -affected areas.  \\n8. Retail and E -commerce:  \\n• E-commerce platforms use object detection to enable visual search, where users can \\nsearch for products using images rather than text. It also helps in recommending visually \\nsimilar products to customers.  \\n9. Augmented Reality (AR):  \\n• AR ap plications rely on object detection to recognize and track physical objects or \\nmarkers in the environment and overlay digital content, enhancing the user's experience.  \\n10. Sports Analysis:  \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-3_DL.pdf', 'page': 3}, page_content=\"• Object detection is used in sports analytics to track players, the ball , and key events \\nduring games. It provides insights for coaching, player performance analysis, and \\naudience engagement.  \\n11. Document Scanning and OCR:  \\n• Optical Character Recognition (OCR) systems use object detection to locate and \\nrecognize text within scanned documents, enabling automated text extraction and \\nconversion.  \\n12. Environmental Conservation:  \\n• Deep learning -based object detection is used to monitor and protect endangered species \\nby tracking animal populations and detecting illegal poaching activities.  \\n13. Traff ic Management:  \\n• Traffic cameras equipped with object detection capabilities help monitor traffic flow, \\ndetect accidents, and manage traffic signals more efficiently.  \\n14. Retail Checkout -Free Stores:  \\n• In cashier -less stores, object detection is used to track prod ucts selected by customers, \\nautomatically adding them to their digital shopping cart.  \\n15. Human -Computer Interaction:  \\n• Object detection facilitates gesture recognition and interactions with devices like \\nsmartphones and augmented reality headsets.  \\nThese applicat ions highlight the versatility of deep learning -based object detection in various domains, \\nfrom enhancing safety and security to improving efficiency and user experiences. As deep learning \\nmodels continue to evolve, object detection capabilities are expect ed to further advance in accuracy and \\nreal-time performance.  \\n \\nAutomatic image captioning  \\nAutomatic image captioning is a fascinating application of deep learning in computer vision that \\ninvolves generating human -like textual descriptions for images. Deep l earning models have been \\nremarkably successful in this domain, providing natural language descriptions for a wide range of \\nimages. Here's how automatic image captioning works and some of its key applications:  \\nHow Automatic Image Captioning Works:  \\n1. Image Fea ture Extraction:  Initially, a deep convolutional neural network (CNN) is employed \\nto extract high -level features from the input image. These features capture essential information \\nabout objects, scenes, and textures in the image.  \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-3_DL.pdf', 'page': 4}, page_content='2. Sequence -to-Sequence Model : The extracted image features are then passed to a sequence -to-\\nsequence model, often based on recurrent neural networks (RNNs) or transformer architectures. \\nThis model is responsible for generating a sequence of words that form the image caption.  \\n3. Language  Model Training:  The RNN or transformer model is trained on a large dataset of \\npaired images and captions. During training, the model learns the relationships between image \\nfeatures and corresponding textual descriptions.  \\n4. Caption Generation:  Once trained, the model takes an image as input and generates a sequence \\nof words, typically one word at a time. At each step, the model predicts the next word based on \\nthe image features and the previously generated words. This process continues until an end -of-\\nsentenc e token is generated or a predefined maximum caption length is reached.  \\n5. Decoding:  Several decoding strategies can be used, such as greedy decoding (selecting the word \\nwith the highest probability at each step) or beam search (exploring multiple word sequences to \\nfind the most likely caption).  \\nApplications of Automatic Image Captioning:  \\n1. Accessibility:  Automatic image captioning is vital for making visual content accessible to \\nindividuals with visual impairments. It provides spoken or braille descriptions of images to \\nenhance their understanding and participation in online content.  \\n2. Conten t Recommendation:  Content recommendation systems can use image captions to better \\nunderstand the content of images and recommend relevant articles, products, or videos to users.  \\n3. Image Indexing and Retrieval:  Image captions serve as textual metadata, making  it easier to \\nsearch for and retrieve specific images from large databases or collections.  \\n4. Social Media:  Automatic image captioning enhances the user experience on social media \\nplatforms by providing informative captions for images and helping users quickly understand the \\ncontent.  \\n5. E-commerce:  E-commerce websites use image captions to provide detailed product  descriptions \\nand improve search engine optimization (SEO) for product listings.  \\n6. Education:  In educational contexts, image captions can be used to provide explanations, context, \\nor additional information for visual materials used in textbooks or e -learning  platforms.  \\n7. Content Generation:  Automatic image captioning can be used to generate descriptions for user -\\ngenerated images in social media, blogs, or news articles.  \\n8. Image Retrieval in Content Creation:  Content creators, such as journalists and designers, ca n \\nuse image captions to quickly find and incorporate relevant images into their projects.  \\n9. Tourism and Travel:  Travel websites and apps use image captions to provide descriptions of \\ntourist attractions, destinations, and travel experiences.  \\n10. Medical Imaging:  In medical applications, image captions can provide detailed descriptions of \\nmedical images, aiding in diagnoses and communication between healthcare professionals.  '),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-3_DL.pdf', 'page': 5}, page_content='Automatic image captioning has made visual content more accessible, searchable, and inform ative in \\nvarious domains, offering benefits to both users and content creators. Deep learning has played a pivotal \\nrole in advancing the accuracy and naturalness of generated image captions.  \\nImage generation with Generative Adversarial Networks (GANs)  \\nImag e generation with Generative Adversarial Networks (GANs) is a fascinating application of deep \\nlearning in computer vision. GANs have gained popularity for their ability to generate highly realistic \\nand detailed images from scratch. Here are some key aspect s and applications of GANs in image \\ngeneration:  \\n1. Image Synthesis:  \\n• GANs are used to synthesize images that appear as if they were created by human artists or \\nphotographers. This includes generating realistic faces, artwork, scenes, and more.  \\n• StyleGAN and StyleGAN2 are examples of GAN architectures known for their ability to \\ngenerate high -quality and diverse images with different styles.  \\n2. Super -Resolution:  \\n• GANs can enhance the resolution and quality of low -resolution images. Super -resolution GANs \\n(SRGANs)  take a low -resolution input image and generate a high -resolution version with \\nimproved detail and clarity.  \\n3. Image -to-Image Translation:  \\n• GANs can perform image -to-image translation, where they transform images from one domain to \\nanother. For example, the y can convert sketches into realistic images, turn day photos into night \\nscenes, or change the style of an artwork.  \\n4. Data Augmentation:  \\n• GANs are used to augment datasets for various computer vision tasks. By generating additional \\nrealistic data, GANs help improve the performance of machine learning models, particularly \\nwhen data is limited.  \\n5. Image Inpainting:  \\n• GANs can be applied to fill in missing or damaged parts of images in a visually coherent manner. \\nThis is useful in restoring old or damaged pho tographs or removing unwanted objects from \\nimages.  \\n6. Face Generation:  \\n• GANs can generate highly detailed and realistic faces, often indistinguishable from real human \\nfaces. This has applications in creating digital avatars, character design, and facial ani mation.  \\n7. Text -to-Image Synthesis:  '),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-3_DL.pdf', 'page': 6}, page_content='• GANs can generate images from textual descriptions. Given a text description, a GAN can create \\nan image that matches the described content, which is valuable in graphic design and content \\ngeneration.  \\n8. Art and Creativit y: \\n• GANs have been used to create unique artworks, merging different styles or generating abstract \\nand surreal visuals. They are used by artists to explore new creative possibilities.  \\n9. Video Generation:  \\n• GANs extended to video, known as Video GANs or VGANs , can generate realistic video \\nsequences. This has applications in video editing, special effects, and video game development.  \\n10. 3D Object Generation:  - GANs can generate 3D objects and scenes, which is valuable in computer -\\naided design (CAD), virtual re ality, and game development.  \\n11. Medical Image Generation:  - GANs can generate synthetic medical images for training and testing \\nmachine learning models in medical imaging tasks. They can also be used for data augmentation in \\nhealthcare.  \\n12. Environmental Simulation:  - GANs can simulate natural environments and landscapes, making \\nthem useful in gaming, simulations, and virtual reality experiences.  \\n13. Fashion Design and Retail:  - GANs can generate fashion designs, clothing images, and product \\nimages for e -commerce platforms, allowing customers to preview clothing items in different styles and \\ncolors.  \\n14. Realistic Content Creation:  - GANs can generate realistic backgrounds, objects, and scenes for \\nvideo games, movies, and virtual simulations, enhancing the i mmersive experience.  \\nGANs continue to evolve, and researchers are constantly improving their capabilities in generating \\nincreasingly realistic and diverse images across various domains. This technology has had a profound \\nimpact on creative industries, cont ent generation, and the development of realistic simulations and \\nexperiences.  \\n \\nVideo to text with LSTM models  \\nThe application of deep learning, specifically LSTM (Long Short -Term Memory) models, to convert \\nvideo data into text is known as \"video -to-text\" or \"video captioning.\" This technology has a wide range \\nof applications and use cases:  \\n1. Video Summarization:  LSTM -based video captioning can automatically generate concise and \\ncoherent textual summaries of longer videos. This is valuable for  creating shorter clips that \\ncapture the essence of a video, making it easier to review, share, and index large video \\ncollections.  '),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-3_DL.pdf', 'page': 7}, page_content='2. Accessibility:  Video -to-text conversion benefits individuals who are deaf or hard of hearing. By \\nproviding textual descriptions of spoken content and sound effects, it enhances the accessibility of \\nvideo content.  \\n3. Content Indexing and Retrieval:  Generating textual descri ptions for videos enables efficient \\ncontent indexing and retrieval. Users can search for specific video segments by entering keywords \\nor phrases, and the system can locate relevant portions of videos.  \\n4. Video Surveillance and Security:  LSTM models can be use d to automatically analyze \\nsurveillance camera footage and provide textual descriptions of events, objects, or people in real -\\ntime. This is valuable for security monitoring and forensic analysis.  \\n5. Video Content Recommendation:  Video captions can serve as a valuable source of textual \\ninformation for recommendation systems. By understanding the content of videos, \\nrecommendation algorithms can suggest relevant videos to users based on their preferences and \\ninterests.  \\n6. Video Journalism and Reporting:  In news repo rting and journalism, video -to-text technology \\ncan assist in quickly summarizing and transcribing video interviews, press conferences, or live \\ncoverage, making the content more accessible to readers and viewers.  \\n7. E-Learning and Education:  Video -to-text conv ersion can be used to automatically generate \\ntranscripts and subtitles for educational videos. This aids in language learning, content \\naccessibility, and searchability within educational platforms.  \\n8. Social Media and User -Generated Content:  Social media plat forms can benefit from automatic \\nvideo captioning by providing textual descriptions or transcripts for videos shared by users. This \\nenhances user engagement and accessibility.  \\n9. Multimodal AI Applications:  Video captions can be combined with other forms of d ata, such as \\ntextual information and sensor data, to create multimodal AI applications. For instance, in \\nautonomous vehicles, video captioning can provide textual descriptions of road scenes captured \\nby cameras, aiding in navigation and decision -making.  \\n10. Video Analysis for Research:  Researchers and analysts can use video -to-text technology to \\nanalyze large video datasets for various purposes, including sentiment analysis, behavior \\nrecognition, and content categorization.  \\n11. Entertainment and Media:  In the enter tainment industry, video captioning can be used to \\nautomatically generate subtitles for movies, TV shows, and online streaming content. This \\nenhances accessibility for viewers who prefer or require subtitles.  \\n12. Content Moderation:  Video captions can assist c ontent moderation systems in identifying and \\nflagging inappropriate or harmful content by analyzing both audio and visual content.  \\nVideo -to-text technology has the potential to revolutionize the way we interact with and extract insights \\nfrom video content.  By converting videos into text, it enables easier searching, indexing, accessibility, \\nand analysis of video data, making it a valuable tool across various industries and applications.  '),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-3_DL.pdf', 'page': 8}, page_content=\"Attention models for computer vision tasks  \\nAttention models , particularly in the context of deep learning and computer vision, have gained \\nsignificant attention (pun intended) due to their effectiveness in improving the performance of various \\ntasks. Attention mechanisms allow models to focus on relevant parts of a n input while downplaying less \\nimportant regions. These mechanisms have been applied to various computer vision tasks, and they have \\nenhanced the performance of models significantly. Here are some key computer vision tasks where \\nattention models are applie d: \\n1. Image Classification:  Attention mechanisms in image classification models help the network \\nselectively attend to relevant regions within an image. Instead of treating all parts of an image \\nequally, the model focuses on the most discriminative regions, i mproving classification accuracy.  \\n2. Object Detection:  Attention is applied in object detection models to enhance the localization of \\nobjects within an image. By assigning higher attention weights to object regions, models can \\nprecisely identify object bounda ries and reduce false positives.  \\n3. Image Captioning:  Attention mechanisms play a crucial role in image captioning tasks. When \\ngenerating a textual description for an image, the model focuses on different regions of the image \\nas it generates each word in the caption. This results in more accurate and contextually relevant \\ndescriptions.  \\n4. Visual Question Answering (VQA):  In VQA tasks, where a model answers questions about an \\nimage, attention mechanisms are used to highlight relevant image regions that provide \\ninformation to answer the question. This improves the model's ability to answer questions \\ncorrectly.  \\n5. Image Super -Resolution:  Attention models are applied in image super -resolution tasks to focus \\non low -level image details during the upscaling process. This en hances the quality of the super -\\nresolved images by allocating attention to important image features.  \\n6. Image Generation:  In image generation tasks, such as generating high -resolution images from \\nlow-resolution inputs or creating artistic images, attention mo dels can help control the generation \\nprocess. They allow the model to attend to specific image features or styles.  \\n7. Fine -Grained Classification:  For tasks that require distinguishing between similar categories \\n(e.g., bird species), attention mechanisms help  models focus on distinctive features, making them \\nmore effective at fine -grained classification.  \\n8. Action Recognition:  In action recognition tasks, where models need to identify actions in video \\nsequences, attention can be applied to specific temporal or sp atial regions of the video frames to \\ncapture the most informative frames or segments.  \\n9. Salient Object Detection:  Attention models can be used for salient object detection by \\nhighlighting the most visually distinctive objects or regions within an image, whic h is useful for \\napplications like image cropping and thumbnail generation.  \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-3_DL.pdf', 'page': 9}, page_content=\"10. Video Analysis:  In video analysis, attention mechanisms can be employed to track objects or \\nregions of interest across frames, improving the tracking accuracy and robustness in comp lex \\nscenarios.  \\n11. Visual Saliency Prediction:  Attention models are used to predict visual saliency maps, which \\nindicate the most visually attention -grabbing regions in an image or video. This is valuable for \\napplications like image compression and content -aware image resizing.  \\nAttention models typically incorporate mechanisms like self -attention or soft attention, inspired by the \\nTransformer architecture. These mechanisms allow the model to dynamically weight the importance of \\ndifferent spatial or temporal regions when processing data, resulting  in improved performance and better \\ninterpretability for various computer vision tasks.  \\n \\nIntroduction to NLP and Vector Space Model of Semantics  \\n \\nDeep learning has had a transformative impact on Natural Language Processing (NLP), a field that \\nfocuses on en abling computers to understand, interpret, and generate human language. One of the \\nfundamental concepts in NLP is the Vector Space Model of Semantics, which forms the basis for many \\nNLP applications. Here's an introduction to NLP and the Vector Space Model , along with some \\napplications of deep learning in NLP:  \\n1. Introduction to NLP:  \\n• NLP is a subfield of artificial intelligence that deals with the interaction between computers and \\nhuman language. Its primary goal is to enable machines to understand, interpr et, and generate \\nhuman language in a way that is both meaningful and useful.  \\n• NLP encompasses a wide range of tasks, including text classification, sentiment analysis, \\nmachine translation, speech recognition, question answering, and more.  \\n2. Vector Space Mo del of Semantics:  \\n• The Vector Space Model (VSM) of semantics is a mathematical framework used to represent \\nwords and documents in a high -dimensional vector space.  \\n• In VSM, each word is represented as a vector, and the relationships between words are captured  \\nthrough vector operations. Words with similar meanings have vectors that are closer in space.  \\n• VSM is a foundational concept in NLP and forms the basis for various semantic analysis and \\nword embedding techniques, such as Word2Vec, GloVe, and FastText.  \\nAppl ications of Deep Learning to NLP:  \\n1. Word Embeddings:  Deep learning models, such as Word2Vec, GloVe, and FastText, learn \\ndense vector representations (embeddings) for words. These embeddings capture semantic \\nrelationships between words and are used as feature s in NLP tasks.  \"),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-3_DL.pdf', 'page': 10}, page_content='2. Text Classification:  Deep learning models, including Convolutional Neural Networks (CNNs) \\nand Recurrent Neural Networks (RNNs), are applied to tasks like sentiment analysis, spam \\ndetection, and topic classification, achieving state -of-the-art results.  \\n3. Named Entity Recognition (NER):  NER models use deep learning techniques to identify and \\nclassify named entities (e.g., names of people, organizations, and locations) in text documents.  \\n4. Machine Translation:  Deep learning has revolutionized machi ne translation systems, with \\nmodels like Transformer and its variants (e.g., BERT) achieving impressive results in translating \\ntext between languages.  \\n5. Question Answering:  Deep learning models, particularly Transformers, are used in question \\nanswering syste ms, where they can read and comprehend textual documents to answer questions \\naccurately.  \\n6. Text Generation:  Recurrent Neural Networks (RNNs) and Transformers are employed for text \\ngeneration tasks, including language modeling, chatbot development, and conten t generation for \\ncreative writing and advertising.  \\n7. Speech Recognition:  Deep learning models, such as Long Short -Term Memory networks \\n(LSTMs) and Convolutional Neural Networks (CNNs), have significantly improved the accuracy \\nof speech recognition systems, e nabling applications like voice assistants.  \\n8. Document Summarization:  Deep learning models can summarize long documents by \\nidentifying and extracting the most important sentences or phrases, making it easier for users to \\ngrasp the key information.  \\n9. Topic Mode ling:  Deep learning techniques are used in topic modeling to identify latent topics \\nwithin large text corpora. Models like Latent Dirichlet Allocation (LDA) are combined with deep \\nlearning for improved results.  \\n10. Dialog Systems:  Deep learning -based dialog systems and chatbots are developed to engage in \\nnatural language conversations with users, offering customer support, information retrieval, and \\nmore.  \\n11. Text -to-Speech (TTS):  Deep learning models like WaveNet are used in TTS syste ms to \\ngenerate human -like speech from text inputs, improving the quality of synthesized speech.  \\n12. Emotion Analysis:  Deep learning models can analyze text to determine the emotional tone or \\nsentiment expressed in social media posts, customer reviews, and othe r text sources.  \\nDeep learning has revolutionized NLP by enabling models to learn complex language patterns and \\nrepresentations directly from data. This has led to significant advancements in various NLP applications, \\nmaking them more accurate, adaptable, a nd capable of handling real -world language understanding and \\ngeneration tasks.  \\n \\n '),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-3_DL.pdf', 'page': 11}, page_content=' \\nWord Vector Representations: Continuous Skip -Gram Model, \\nContinuous Bag -of-Words model (CBOW)  \\nWhat does word embedding mean?  \\nWord embedding is just a fancy way of saying numerical representation of words. A good analogy would \\nbe how we use the RGB representation for colors.  \\nWhy do we need word embedding?  \\nAs a human, intuitively speaking, it doesn’t make much sense in wanting to represent words or any other \\nobject in  the universe using numbers because numbers are used for quantification and why would one \\nneed to quantify words?  \\nWhen in science, we say speed of my car is 45 km/hr we gain a sense of how fast/slow we are driving. If \\nwe say my friend is driving at 60 km/h r, we can compare which one of us is going faster. Furthermore, we \\ncan calculate where we will be at a certain point in time, when we will reach our destination given we \\nknow the distance of our journey etc . Similarly, outside of science, we use numbers to  quantify a quality, \\nwhen we quote the price of an object we try to quantify its worth, the size of a garment we try to quantify \\nthe body proportions it will fit best.  \\nAll of these representations make sense because by using numbers we have made analysis a nd \\ncomparisons based on those qualities much much easier. What’s worth more a shoe or a purse? Well, as \\ndifferent as those two objects are, one way to answer that is to compare their prices. Other than the \\nquantification aspect, there isn’t any thing else to be gained by this representation.  \\nNow that we know numerical representation of objects aids in analysis by quantifying a certain quality, \\nthe question is what quality of words do we want to quantify?  \\nThe answer to that is, we want to quantify the  semant ics. We want to represent words in such a manner \\nthat it captures its meaning in a way humans do. Not the exact meaning of the word but a contextual one. \\nFor example, when I say the word  see, we know exactly what action — the context — I’m talking about, \\neven though we might not be able to quote its meaning, the kind we would find in a dictionary, of the top \\nof our head.  \\nWhat are good quality word embedding and how to generate them?  \\nThe simplest word embedding you can have is using one -hot vectors. If you h ave 10,000 words in your \\nvocabulary, then you can represent each word as a 1x10,000 vector.  \\nFor a simple example, if we have 4 words — mango, strawberry, city, Delhi — in our vocabulary then we \\ncan represent them as following:  \\n• Mango [1, 0, 0, 0]  \\n• Strawberry  [0, 1, 0, 0]  \\n• City [0, 0, 1, 0]  '),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-3_DL.pdf', 'page': 12}, page_content='• Delhi [0, 0, 0, 1]  \\n \\nThere are a few problems with the above approach, firstly, our size of vectors depends on the size of our \\nvocabulary ( which can be huge). This is a wastage of space and increases algorithm complexity \\nexponentially resulting in the  curse of dimensionalit y. \\nSecondly, these embedding will be closely coupled to their applications, making transfer -learning to a \\nmodel using a different vocabulary of the same s ize, adding/removing words from vocabulary would \\nalmost impossible as it would require to re -train the whole model again.  \\nLastly, the entire purpose of creating embedding is to capture the contextual meaning of the words, which \\nthis representation fails to  do. There is no co -relation between words that have similar meaning or usage.  \\n## Current situation   \\nSimilarity(Mango, Strawberry) == Similarity(Mango, City) == 0 ## Ideal situation  \\nSimilarity(Mango, Strawberry) >> Similarity(Mango, City)** Note: Similarity (a,b) = a.b/(||a||*||b|| ) \\nCosine similarity  \\n \\nContinuous Bag of Words Model (CBOW) and Skip -gram  \\nBoth are architectures to learn the underlying word representations for each word by using neural \\nnetworks.  '),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-3_DL.pdf', 'page': 13}, page_content=' \\nIn the  CBOW  model, the distributed representations of context (or surrounding words) are combined \\nto predict the word in the middle . While in the  Skip -gram  model, the distributed representation of the \\ninput word is used to  predict the context . \\nA prerequisite for any neural network or any su pervised training technique is to have labeled training data. \\nHow do you a train a neural network to predict word embedding when you don’t have any labeled data i.e \\nwords and their corresponding word embedding?  \\nSkip -gram Model  \\nWe’ll do so by creating a “fa ke” task for the neural network to train. We won’t be interested in the inputs \\nand outputs of this network, rather the goal is actually just to learn the weights of the hidden layer that are \\nactually the “word vectors” that we’re trying to learn.  \\nThe fake task for Skip -gram model would be, given a word, we’ll try to predict its neighboring words. \\nWe’ll define a neighboring word by the window size — a hyper -parameter.  \\n \\n'),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-3_DL.pdf', 'page': 14}, page_content=' \\nGiven the sentence:  \\n \\n“I will have orange  juice  and eggs for breakfast.”  \\n \\nand a window size of 2, if the target word is  juice,  its neighboring words will be  ( have, orange, and, \\neggs).  Our input and target word pair would be (juice, have), (juice, orange), (juice, and), (juice, eggs).  \\nAlso note that within the sample window, proximity  of the words to the source word plays no role. So  have, \\norange, and,  and eggs will be treated the same while training.  \\n'),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-3_DL.pdf', 'page': 15}, page_content=' \\n \\nFig: Architecture for skip -gram mode  \\nThe dimensions of the input vector will be 1xV — where V is the  number of words in the \\nvocabulary — i.e one -hot representation of the word. The single hidden layer will have \\ndimension VxE, where E is the size of the word embedding and is a hyper -parameter. The \\noutput from the hidden layer would be of the dimension 1xE, which we will feed int o \\nan softmax layer . The dimensions of the output layer will be 1xV, where each value in the \\nvector will be the probability score of the target word at that position.  \\nAccording to our earlier example if we have a vector [0.2, 0.1, 0.3, 0.4], the probability of \\nthe word being  mango  is 0.2,  strawberry  is 0.1,  city is 0.3 and  Delhi  is 0.4.  \\nThe back propagation for training samples corresponding to a source word i s done in one \\nback pass. So for  juice,  we will complete the forward pass for all 4 target words  (have, \\norange, and, eggs).  We will then calculate the errors vectors  [1xV dimension] \\ncorresponding to each target word. We will now have 4 1xV error vectors and  will perform \\nan element -wise sum to get a 1xV vector. The weights of the hidden layer will be updated \\nbased on this cumulative 1xV error vector.  \\nCBOW  \\nThe fake task in CBOW is somewhat similar to Skip -gram, in the sense that we still take a \\npair of words a nd teach the model that they co -occur but instead of adding the errors we \\nadd the input words for the same target word.  \\n'),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-3_DL.pdf', 'page': 16}, page_content='The dimension of our hidden layer and output layer will remain the same. Only the \\ndimension of our input layer and the calculation of hi dden layer activations will change, if \\nwe have 4 context words for a single target word, we will have 4 1xV input vectors. Each \\nwill be multiplied with the VxE hidden layer returning 1xE vectors. All 4 1xE vectors will \\nbe averaged element -wise to obtain th e final activation which then will be fed into the \\nsoftmax layer.  \\nSkip -gram : works well with a small amount of the training data, represents well even rare \\nwords or phrases.  \\n \\nCBOW : several times faster to train than the skip -gram, slightly better accuracy for the \\nfrequent words.  \\n \\nGloVe  \\n \\n\"GloVe \" stands for \"Global Vectors for Word Representation,\" and it is a word embedding model used \\nfor learning vector representations (embeddings) of words based on their co -occurrence statistics in a large \\ncorpus of text. GloVe was introduced by Jeffrey Pennin gton, Richard Socher, and Christopher D. Manning \\nin their 2014 paper titled \"GloVe: Global Vectors for Word Representation.\"  \\nHere are some key points about GloVe and its evaluations:  \\nGloVe Model:  \\n• GloVe is a shallow neural network -based model for word embed dings.  \\n• It learns word vectors by capturing the semantic and syntactic relationships between words based \\non their word co -occurrence statistics.  \\n• The model aims to find word embeddings that encode the information about how frequently and \\nclosely words co -occur in the training corpus.  \\nEvaluations of GloVe:  \\n1. Word Similarity Evaluation:  GloVe word vectors are evaluated by measuring the similarity \\nbetween word pairs using various metrics like cosine similarity. Human -annotated word similarity \\ndatasets (e.g., WordS im-353) are often used for this evaluation. The model is considered successful \\nif words with similar meanings have higher similarity scores.  \\n2. Word Analogy Evaluation:  GloVe is evaluated on word analogy tasks, such as \"king - man + \\nwoman = queen.\" The model\\' s embeddings should exhibit the ability to perform vector arithmetic, \\nreflecting semantic relationships between words (e.g., gender, verb tenses, etc.).  '),\n",
       " Document(metadata={'source': '/content/sample_data/data/unit-3_DL.pdf', 'page': 17}, page_content=\"3. Word Intrusion Detection:  In this evaluation, one word is replaced with an unrelated word in a \\nset of w ords. The model's embeddings should detect the intruder word as the most dissimilar word \\nin the set.  \\n4. Word Sense Disambiguation:  GloVe embeddings can be used to improve word sense \\ndisambiguation tasks by providing contextually informative word representatio ns that capture \\ndifferent senses of polysemous words.  \\n5. Downstream NLP Tasks:  GloVe embeddings are often used as pre -trained word vectors in \\nvarious downstream NLP tasks like sentiment analysis, named entity recognition, machine \\ntranslation, and text classif ication. The performance improvement in these tasks is a practical \\nevaluation of the quality of the learned word representations.  \\n6. Visualization:  Visualization techniques, such as t -SNE (t -Distributed Stochastic Neighbor \\nEmbedding), are used to visualize the learned word vectors in lower -dimensional space to gain \\ninsights into their clustering and relationships.  \\n7. Transfer Learning:  Evaluating the tr ansferability of pre -trained GloVe embeddings to new \\ndomains and languages is another important aspect. The embeddings should generalize well to \\ndifferent tasks and languages.  \\nGloVe embeddings have been widely adopted in natural language processing tasks d ue to their ability to \\ncapture semantic relationships and their high -quality word representations. However, it's essential to note \\nthat the quality of GloVe embeddings can also depend on the size and quality of the training corpus, as \\nwell as the specific use case and evaluation metrics chosen for a given NLP task.  \\n \")]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_doc(directory):\n",
    "    from langchain_community.document_loaders import PyPDFLoader # import PyPDFLoader within the function\n",
    "    loaders = [PyPDFLoader(os.path.join(directory, fn)) for fn in os.listdir(directory)] # create a list of PyPDFLoaders\n",
    "    documents = []\n",
    "    for loader in loaders:\n",
    "        documents.extend(loader.load()) # load documents from each loader\n",
    "    return documents\n",
    "\n",
    "doc=read_doc('/content/sample_data/data')\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DOdbokKjbDOv",
    "outputId": "c9f7e16d-2d65-4cfa-f2e1-49bfea62255d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '/content/sample_data/data/Unit-4_DL.pdf', 'page': 0}, page_content='Unit -4 \\n \\nWord similarity is a fundamental concept in natural language processing, and there are several \\napplications where measuring the similarity or relatedness between words is crucial. Some of these \\napplications include:  \\n1. Information Retrieval : In information retrieval systems, understanding the similarity between \\nuser queries and documents is essential for ranking search results. Word similarity measures can \\nhelp identify documents that are semantically related to a user\\'s query.  \\n2. Text Summarization : When generating text summaries, it\\'s important to ensure that the \\nsummary captures the key information in a document. Word similarity can be used to identify \\nimportant words and phrases in the source text and select them for inclusion in the summary.  \\n3. Mac hine Translation : In machine translation systems, word similarity can be useful for aligning \\nwords in the source and target languages. Measuring similarity between words in different \\nlanguages can aid in selecting appropriate translations.  \\n4. Lexical Semantic s: Word similarity is a valuable resource in lexical semantics. It can be used to \\ndiscover synonyms, antonyms, hypernyms, and hyponyms. Lexical databases and lexical \\nontologies often rely on word similarity measures to organize and relate words.  \\n5. Word Sense  Disambiguation : Word sense disambiguation is the task of determining the correct \\nsense of a word in context. Word similarity can help disambiguate words by comparing the \\ncontext in which a word appears with the various senses of that word.  \\n6. Semantic Search  and Recommendation Systems : In search engines and recommendation \\nsystems, word similarity can be used to find documents, products, or content that is semantically \\nsimilar to a user\\'s query or interests. This helps improve the relevance of search results a nd \\nrecommendations.  \\n7. Plagiarism Detection : Detecting plagiarism often involves comparing the similarity of text \\npassages. Word similarity measures can be used to identify similarities between documents and \\nhighlight potential instances of plagiarism.  \\n8. Word E mbeddings : Word embeddings, such as Word2Vec, GloVe, and FastText, are trained to \\ncapture word similarity in vector space. These embeddings are widely used in various NLP tasks, \\nand they provide a way to quantify word similarity based on the distributional  hypothesis, which \\nstates that words with similar meanings tend to occur in similar contexts.  \\n9. Analogical Reasoning : Word similarity is a key component of analogical reasoning tasks. \\nModels like Word2Vec have been used to solve analogical word relationships , such as \"king - \\nman + woman = queen,\" by leveraging word similarity.  \\nIn all these applications, the choice of word similarity measure or embedding technique depends on the \\nspecific requirements of the task and the corpus of text data being analyzed. Diff erent measures, such as ')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sdvFGut3kXwZ"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
    "os.environ['PINECONE_API_KEY'] = userdata.get('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XdZro0VoWs1"
   },
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "index_name = \"ragchatbot\"\n",
    "\n",
    "## Split our document into chunk\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "split_docs = text_splitter.split_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rBe0Sevtp2wf",
    "outputId": "659f7709-8c8d-432f-a0bc-58fe407f9ddf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '/content/sample_data/data/Unit-4_DL.pdf', 'page': 0}, page_content='Unit -4 \\n \\nWord similarity is a fundamental concept in natural language processing, and there are several \\napplications where measuring the similarity or relatedness between words is crucial. Some of these \\napplications include:  \\n1. Information Retrieval : In information retrieval systems, understanding the similarity between \\nuser queries and documents is essential for ranking search results. Word similarity measures can \\nhelp identify documents that are semantically related to a user\\'s query.  \\n2. Text Summarization : When generating text summaries, it\\'s important to ensure that the \\nsummary captures the key information in a document. Word similarity can be used to identify \\nimportant words and phrases in the source text and select them for inclusion in the summary.  \\n3. Mac hine Translation : In machine translation systems, word similarity can be useful for aligning \\nwords in the source and target languages. Measuring similarity between words in different \\nlanguages can aid in selecting appropriate translations.  \\n4. Lexical Semantic s: Word similarity is a valuable resource in lexical semantics. It can be used to \\ndiscover synonyms, antonyms, hypernyms, and hyponyms. Lexical databases and lexical \\nontologies often rely on word similarity measures to organize and relate words.  \\n5. Word Sense  Disambiguation : Word sense disambiguation is the task of determining the correct \\nsense of a word in context. Word similarity can help disambiguate words by comparing the \\ncontext in which a word appears with the various senses of that word.  \\n6. Semantic Search  and Recommendation Systems : In search engines and recommendation \\nsystems, word similarity can be used to find documents, products, or content that is semantically \\nsimilar to a user\\'s query or interests. This helps improve the relevance of search results a nd \\nrecommendations.  \\n7. Plagiarism Detection : Detecting plagiarism often involves comparing the similarity of text \\npassages. Word similarity measures can be used to identify similarities between documents and \\nhighlight potential instances of plagiarism.  \\n8. Word E mbeddings : Word embeddings, such as Word2Vec, GloVe, and FastText, are trained to \\ncapture word similarity in vector space. These embeddings are widely used in various NLP tasks, \\nand they provide a way to quantify word similarity based on the distributional  hypothesis, which \\nstates that words with similar meanings tend to occur in similar contexts.  \\n9. Analogical Reasoning : Word similarity is a key component of analogical reasoning tasks. \\nModels like Word2Vec have been used to solve analogical word relationships , such as \"king - \\nman + woman = queen,\" by leveraging word similarity.  \\nIn all these applications, the choice of word similarity measure or embedding technique depends on the \\nspecific requirements of the task and the corpus of text data being analyzed. Diff erent measures, such as')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from re import split\n",
    "split_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5Gb1CK3qHUw"
   },
   "outputs": [],
   "source": [
    "vectorstores = PineconeVectorStore.from_documents(split_docs, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWxndRLnutN_"
   },
   "outputs": [],
   "source": [
    "query = \"what is neural network?\"\n",
    "\n",
    "similar_docs = vectorstores.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tVrFWsZlvfra",
    "outputId": "bbab3804-7945-468b-d4d8-e56d62d51b04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='8c2ee895-1705-4084-a931-ba054c5626f0', metadata={'page': 13.0, 'source': '/content/sample_data/data/unit-1_DL.pdf'}, page_content='Typically, dropout is applied to the hidden layers of a neural network, and the dropout rate is a \\nhyperparameter that determines the probability of dropping out each neuron (common values are around \\n0.2 to 0.5). During inference or when making predictions, dropout is usually turned off, and the entire \\nnetwork is used.  \\nIn summary, regularization techniques like L1 and L2 regularization add penalties to the loss function \\nbased on the magnitude of the weights to prevent overfitting. Dropout, on the other hand, randomly \\ndeactivates neurons during training to encourage the n etwork to learn more robust features and reduce \\noverfitting. These techniques are essential tools for improving the generalization and performance of \\nneural networks on unseen data.  \\nConvolutional Neural Networks  \\n \\nPeople are getting more fascinated with Art ificial Intelligence, Machine Learning, and Deep Learning in \\nthe current world. These fields have been using a wide range of techniques and algorithms to give humans \\nthe best results. If you specifically consider deep learning, it uses neural networks to m imic the human \\nbrain. Several kinds of neural networks are used in a wide range of applications of deep learning like \\nimage processing, image segmentation, self -driving cars, etc. One such popular neural network is CNN \\nwhich stands for Convolutional Neural  Network.  \\nWhat is CNN?  \\nConvolutional Neural Networks (CNN, or ConvNet) are a type of multi -layer neural network that is meant \\nto discern visual patterns from pixel images. In CNN, ‘convolution’ is referred to as the mathematical \\nfunction. It’s a type of li near operation in which you can multiply two functions to create a third function \\nthat expresses how one function’s shape can be changed by the other. In simple terms, two images that are \\nrepresented in the form of two matrices, are multiplied to provide a n output that is used to extract \\ninformation from the image. CNN is similar to other neural networks, but because they use a sequence of \\nconvolutional layers, they add a layer of complexity to the equation. CNN cannot function without \\nconvolutional layers.  In a variety of computer vision tasks, CNN artificial neural networks have risen to \\nthe top. It has picked people’s interest in a variety of fields.  \\nA convolutional neural network is made up of numerous layers, such as convolution layers, pooling layers, \\nand fully connected layers, and it uses a backpropagation algorithm to learn spatial hierarchies of data \\nautomatically and adaptively. You will learn more about these terms in the following section.  \\nTypical CNN Architecture'),\n",
       " Document(id='fe935b7a-ac11-4ba2-9914-b1ff29b04775', metadata={'page': 0.0, 'source': '/content/sample_data/data/unit-1_DL.pdf'}, page_content=\"Unit -1  \\nFeedforward neural network  \\n \\nA feedforward neural network, also known as a feedforward artificial neural network or simply a \\nfeedforward neural network (FNN), is a type of artificial neural network that's structured in layers, with \\ninformation flowing in one direction, from the input layer to the output layer. It's one of the fundamental \\narchitectures in deep learning and is often used for various tasks such as classification, regression, and \\nfunction approximation.  \\nHere are some key characteris tics and components of feedforward neural networks:  \\n1. Layers : A feedforward neural network typically consists of three types of layers:  \\n• Input Layer : This is the layer where data is fed into the network. Each node in the input \\nlayer represents a feature or in put variable.  \\n• Hidden Layers : These are one or more layers between the input and output layers. Each \\nnode (neuron) in a hidden layer performs a weighted sum of its inputs and applies an \\nactivation function to produce an output. The presence of hidden layers  allows the network \\nto learn complex relationships in the data.  \\n• Output Layer : The output layer produces the final prediction or output of the network. \\nThe number of nodes in the output layer depends on the nature of the task (e.g., binary \\nclassification, m ulti-class classification, regression), and the activation function used in this \\nlayer may vary accordingly.  \\n2. Connections and Weights : Each connection between nodes in adjacent layers has an associated \\nweight. These weights are learned during training to en able the network to make accurate \\npredictions. The weighted sum of inputs is calculated for each neuron, and an activation function \\nis applied to this sum to produce the neuron's output.  \\n3. Activation Functions : Activation functions introduce non -linearity in to the network, allowing it \\nto model complex relationships. Common activation functions include ReLU (Rectified Linear \\nUnit), sigmoid, and tanh. Each neuron in the hidden layers and the output layer typically applies \\nan activation function to its weighted sum of inputs.\"),\n",
       " Document(id='87346e41-2c73-4591-9a1d-0397f6651a8b', metadata={'page': 0.0, 'source': '/content/sample_data/data/Unit-2_DL.pdf'}, page_content='Unit -2 \\nRecurrent Neural Network (RNN)  \\nA recurrent neural network ( RNN ) is a kind of artificial neural network mainly used in  speech \\nrecognition  and natural language processing  (NLP). RNN is used in deep learning and in the \\ndevelopment of models that imitate the activity of neurons in the human  brain . \\nRecurrent Networks are designed to  recognize patterns  in sequences of data, such as  text, genomes, \\nhandwriting, the spoken word,  and numerical  time series data emanating from sensors, stock markets, \\nand g overnment agencies.  \\nA recurrent neural network looks similar to a traditional neural network except that a memory -state is \\nadded to the neurons. The computation is to include a simple memory.  \\nThe recurrent neural network is a type of deep learning -oriented  algorithm, which follows a sequential \\napproach. In neural networks, we always assume that each input and output is dependent on all other \\nlayers. These types of neural networks are called recurrent because they sequentially perform \\nmathematical computatio ns. \\n \\nThe recurrent network first performs the conversion of independent activations into dependent ones. It \\nalso assigns the same weight and bias to all the layers, which reduces the complexity of RNN of \\nparameters. And it provides a standard platform for  memorization of the previous outputs by providing \\nprevious output as an input to the next layer.  \\nThese three layers having the same weights and bias, combine into a single recurrent unit.  \\n \\nFor calculating the current state - \\nht =f(h t-1, Xt)'),\n",
       " Document(id='b50beea1-d82b-4949-bfef-db575d52e640', metadata={'page': 21.0, 'source': '/content/sample_data/data/Unit-2_DL.pdf'}, page_content=\"• They have been widely used in natural language processing tasks, such as machine translation and \\ntext summarization.  \\n• Attention mechanisms allow models to weigh the importanc e of different parts of the input \\nsequence, which is particularly helpful when dealing with long sequences.  \\nMemory Models : \\n• Memory models in the context of deep learning refer to architectures that incorporate external \\nmemory components.  \\n• These models have t he ability to read from and write to memory, which can help them store and \\nretrieve information over longer sequences.  \\n• Memory -augmented neural networks, like the Neural Turing Machine (NTM) and Differentiable \\nNeural Computer (DNC), are examples of models w ith memory components. They have shown \\npromise in tasks that require complex reasoning and sequential processing.  \\nIn summary, autoencoders are used for data compression and feature learning, DBMs are generative \\nmodels capable of capturing complex probabili ty distributions, attention models help focus on important \\ninformation in sequences, and memory models incorporate external memory for tasks involving longer \\nsequences and complex reasoning. Each of these models has found applications in different areas of  deep \\nlearning and machine learning.  \\nDynamic Memory Networks (DMNs ) \\nDynamic Memory Networks (DMNs) are a type of neural network architecture designed for question -\\nanswering and reasoning tasks, particularly in the context of natural language understanding.  DMNs were \\nintroduced to address the limitations of traditional neural networks in handling complex, multi -step \\nreasoning and inference tasks. Here's a brief overview of Dynamic Memory Networks:  \\n1. Memory Network : At the core of a DMN is a memory network, whi ch is designed to store and \\nretrieve information efficiently. The memory network typically consists of an external memory \\nmatrix that can be read from and written to. Each row in the matrix corresponds to a piece of \\ninformation.  \\n2. Episodic Memory : DMNs inclu de an episodic memory component, which allows the network to \\nread and write to the memory matrix in an iterative manner. This episodic memory mechanism is \\ncrucial for handling sequential and multi -step reasoning tasks.  \\n3. Input Representation : The input to a DMN usually includes a sequence of words or symbols \\nrepresenting the context or passage of text, a question, and sometimes additional information. \\nThese inputs are encoded into vector representations, often using recurrent neural networks \\n(RNNs) or attenti on mechanisms.  \\n4. Attention Mechanism : DMNs incorporate attention mechanisms to focus on relevant information \\nwithin the context or memory matrix. Attention weights are computed to emphasize important \\nelements in the memory based on the current question or context.\")]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tg9ZxSPjvigV",
    "outputId": "c8afed35-9bc3-438d-e9d3-f3c8dd3cfe97"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-46-8bd867ab0945>:5: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'what is neural network?',\n",
       " 'result': \"A neural network, also known as an artificial neural network (ANN), is a computational model inspired by the way biological neural networks in the human brain process information. It consists of interconnected nodes, or neurons, organized in layers. These layers include an input layer, one or more hidden layers, and an output layer. Each connection between neurons has an associated weight, which is adjusted during the training process to minimize the error in the network's predictions.\\n\\nHere are some key characteristics and components of neural networks:\\n\\n1. **Layers**:\\n   - **Input Layer**: This is where data is fed into the network. Each node in the input layer represents a feature or input variable.\\n   - **Hidden Layers**: These are intermediate layers between the input and output layers. Each neuron in a hidden layer performs a weighted sum of its inputs and applies an activation function to produce an output. The presence of hidden layers allows the network to learn complex relationships in the data.\\n   - **Output Layer**: This layer produces the final prediction or output of the network. The number of nodes in the output layer depends on the nature of the task (e.g., binary classification, multi-class classification, regression).\\n\\n2. **Connections and Weights**: Each connection between nodes in adjacent layers has an associated weight. These weights are learned during training to enable the network to make accurate predictions. The weighted sum of inputs is calculated for each neuron, and an activation function is applied to this sum to produce the neuron's output.\\n\\n3. **Activation Functions**: Activation functions introduce non-linearity into the network, allowing it to model complex relationships. Common activation functions include ReLU (Rectified Linear Unit), sigmoid, and tanh. Each neuron in the hidden layers and the output layer typically applies an activation function to its weighted sum of inputs.\\n\\nNeural networks are used in a wide range of applications, including image and speech recognition, natural language processing, and many other tasks that require pattern recognition and data analysis. They are a fundamental component of deep learning, which involves training large neural networks with many layers (deep architectures) to solve complex problems.\"}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstores.as_retriever()\n",
    ")\n",
    "\n",
    "qa.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUqaZ0kfyJpG",
    "outputId": "0fb51b25-3487-48b2-b1d3-043f29114288"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'what is deep learning?',\n",
       " 'result': 'Deep learning is a subset of machine learning that involves the use of artificial neural networks with many layers (hence \"deep\") to model and understand complex patterns in data. It is particularly effective for tasks where traditional machine learning algorithms struggle, such as image and speech recognition, natural language processing, and more. Here are some key aspects of deep learning:\\n\\n1. **Neural Networks**: Deep learning models are based on neural networks, which are computational structures inspired by the human brain. These networks consist of layers of interconnected nodes (neurons) that process input data and learn to make predictions or classifications.\\n\\n2. **Multiple Layers**: Unlike traditional neural networks, deep learning models have many layers (hence \"deep\"), which allow them to learn hierarchical representations of data. Each layer extracts increasingly abstract features from the input data.\\n\\n3. **Learning from Data**: Deep learning models learn directly from raw data. They can automatically discover the representations needed for feature detection or classification from the data, without the need for manual feature engineering.\\n\\n4. **Backpropagation**: This is a key algorithm used in training deep learning models. It involves adjusting the weights of the network in response to the error rate (loss) obtained in the previous iteration, allowing the model to improve its accuracy over time.\\n\\n5. **Applications**: Deep learning has been successfully applied to a wide range of tasks, including:\\n   - **Image and Video Analysis**: Tasks like image classification, object detection, and image segmentation.\\n   - **Natural Language Processing (NLP)**: Tasks like text classification, named entity recognition, machine translation, and text generation.\\n   - **Speech Recognition**: Converting spoken language into text.\\n   - **Autonomous Systems**: Enabling self-driving cars and robots to understand and navigate their environments.\\n\\n6. **Popular Architectures**: Some well-known deep learning architectures include Convolutional Neural Networks (CNNs) for image-related tasks, Recurrent Neural Networks (RNNs) and Long Short-Term Memory networks (LSTMs) for sequential data like text and speech, and Transformers for various NLP tasks.\\n\\n7. **Software Libraries**: There are several deep learning libraries and frameworks, such as TensorFlow, PyTorch, and Keras, which provide tools and pre-implemented algorithms to facilitate the development and training of deep learning models.\\n\\nDeep learning has revolutionized many fields by enabling models to learn complex patterns and representations directly from data, leading to significant advancements in various applications.'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.invoke({\"query\": \"what is deep learning?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9arKIAkqyuIW",
    "outputId": "1661dfc6-9fd8-429a-f918-5fa5efcc92db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'what is Automatic image captioning?',\n",
       " 'result': 'Automatic image captioning is a deep learning application in computer vision that involves generating human-like textual descriptions for images. The process typically involves several steps:\\n\\n1. **Image Feature Extraction**: A deep convolutional neural network (CNN) is used to extract high-level features from the input image. These features capture essential information about objects, scenes, and textures in the image.\\n\\n2. **Sequence-to-Sequence Model**: The extracted image features are passed to a sequence-to-sequence model, often based on recurrent neural networks (RNNs) or transformer architectures. This model generates a sequence of words that form the image caption.\\n\\n3. **Language Model Training**: The RNN or transformer model is trained on a large dataset of paired images and captions. During training, the model learns the relationships between image features and corresponding textual descriptions.\\n\\n4. **Caption Generation**: Once trained, the model takes an image as input and generates a sequence of words, typically one word at a time. At each step, the model predicts the next word based on the image features and the previously generated words. This process continues until an end-of-sentence token is generated or a predefined maximum caption length is reached.\\n\\n5. **Decoding**: Several decoding strategies can be used, such as greedy decoding (selecting the word with the highest probability at each step) or beam search (exploring multiple word sequences to find the most likely caption).\\n\\n**Applications of Automatic Image Captioning**:\\n- **Accessibility**: Provides spoken or braille descriptions of images for individuals with visual impairments.\\n- **Content Recommendation**: Helps recommendation systems understand image content to suggest relevant articles, products, or videos.\\n- **Image Indexing and Retrieval**: Serves as textual metadata, making it easier to search for and retrieve specific images.\\n- **Social Media**: Enhances user experience by providing informative captions for images.\\n- **E-commerce**: Provides detailed product descriptions and improves search engine optimization (SEO) for product listings.\\n- **Education**: Offers explanations, context, or additional information for visual materials in textbooks or e-learning platforms.\\n- **Content Generation**: Generates descriptions for user-generated images in social media, blogs, or news articles.\\n- **Image Retrieval in Content Creation**: Helps content creators quickly find and incorporate relevant images into their projects.\\n- **Tourism and Travel**: Provides descriptions of tourist attractions, destinations, and travel experiences.\\n- **Medical Imaging**: Offers detailed descriptions of medical images, aiding in diagnoses and communication between healthcare professionals.\\n\\nAutomatic image captioning has significantly improved the accessibility, searchability, and informativeness of visual content across various domains.'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.invoke({\"query\": \"what is Automatic image captioning?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zCNrHuahzEIo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
